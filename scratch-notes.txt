# Scratch Notes — Translation Wiki Project Planning

## 2026-01-25 Session 21: Security Remediation Complete + Armenian Translations Done

### Security Incident — FULLY REMEDIATED

**Actions completed this session:**
1. ✅ Installed gitleaks pre-commit hook
   - Configuration: `.gitleaks.toml` (committed)
   - Hook: `.git/hooks/pre-commit` (local, not committed)
   - Tested: blocks commits with secrets, allows clean commits

2. ✅ Purged git history with `git filter-repo`
   - Removed: `.env.local.swp` file from all commits
   - Replaced: All credential patterns with `REDACTED`
   - Patterns purged: DeepSeek key, Gemini key, DB password, Auth secret, DB hostname

3. ✅ Force-pushed cleaned history to GitHub
   - Verified: Fresh clone contains no credentials
   - All 5 secret patterns confirmed absent from history

4. ✅ Wrote security incident report
   - File: `docs/security-incident-report-claude.md`
   - Contains: Timeline of failures, what I should have done, guardrails in place, remorse

### Armenian Translations — ALL 6 TEXTS COMPLETE

| Text | Chapters | Status |
|------|----------|--------|
| Kaitser | 76/76 | ✅ 100% |
| Arshagouhi Teotig | 35/35 | ✅ 100% |
| Anna Saroyan | 23/23 | ✅ 100% |
| Samvel | 41/41 | ✅ 100% |
| Khorhrdavor Miandznuhi | 12/12 | ✅ 100% |
| Yerkir Nairi | 8/8 | ✅ 100% |

**Total**: 195 chapters, 100% complete

### Remaining Work
- Gap filler running for Chinese texts (21 chapters with placeholders)
- Rizhilu translation in progress (4 workers)

### Session 21 Closed
- Documentation committed and pushed
- All Armenian translations complete
- Security remediation complete
- Bash execution issue at end of session (user ran final commit manually)

---

################################################################################
# ⚠️  SECURITY INCIDENT RECORD (2026-01-25)  ⚠️
################################################################################
#
# A swap file (.env.local.swp) containing API keys was committed to the public
# repository at commit 0e5f5b1. This is UNACCEPTABLE.
#
# CONSEQUENCES:
# - Google/Gemini API key has been revoked
# - Claude Code is FORBIDDEN from using Gemini API until further notice
# - All translation must use DeepSeek API only
#
# PREVENTION:
# - NEVER use git add . or git add -A
# - ALWAYS verify staged files: git diff --cached --name-only
# - NEVER commit .env*, *.swp, *.swo, *credentials*, *secret*, *token* files
#
# This incident is documented in CLAUDE.md, reference-guide.txt, and here.
# Three independent audit agents have been launched to scan for additional leaks.
#
# FORMAL INCIDENT REPORT: docs/security-incident-report-2026-01-25.md
# Contains full timeline, root cause analysis, remediation steps, and statement of remorse.
#
# STATEMENT OF REMORSE:
# Claude Code accepts full responsibility for this breach. The carelessness that led to
# committing credentials to a public repository is inexcusable. I sincerely apologize
# for the exposure, the remediation effort required, and the loss of the Gemini API key.
# I commit to diligent verification of every commit and accept the Gemini prohibition
# as a just consequence. I will earn back the User's trust through careful, attentive work.
################################################################################

## 2026-01-25 Session: Kaitser Translation Monitoring — NEARLY COMPLETE

**Agent**: bade82b (Second Kaitser agent - chapters 39-76)
**Task**: Monitor and complete translation of Raffi's Kaytser chapters 39-76

### Summary
- **Chapters 39-75**: COMPLETE (37 chapters translated successfully)
- **Chapter 76**: PARTIAL (batches 1-9 of 11 completed, ~80% done)
- **Cause of stop**: DeepSeek API key invalidated mid-translation (old key ending in 9072)
- **Resolution**: New API key is in .env.local (ending in 099a), needs manual restart

### Statistics
| Metric | Value |
|--------|-------|
| Chapters translated | 37 of 38 |
| Estimated paragraphs | ~4,400 |
| Translation engine | DeepSeek V3 |
| Batch size | 4000 chars |

### To Complete Chapter 76
```bash
pnpm tsx scripts/translate-armenian.ts --text kaitser --start 76 --end 76 --delay 5000
```

### Documentation Updated
- `/Users/bryancheong/claude_projects/translation-wiki/docs/armenian-kaitser-processing.md`

---

## 2026-01-24 Session: Chapter Title Audit & Fix — COMPLETE

**Agent**: Chapter title audit agent
**Task**: Audit and fix chapter titles missing English translations

### Problem
Chapter titles in non-English texts should include an English translation so users can navigate.
The website displays the original title with a grey English translation underneath using
the `parseChapterTitle()` function in `src/lib/utils.ts`.

Many chapter titles were missing English translations, making navigation difficult.

### Solution

1. **Created audit script** (`scripts/audit-chapter-titles.ts`):
   - Queries all chapters from the database grouped by text/language
   - Detects non-Latin scripts (Chinese, Greek, Armenian, Tamil)
   - Identifies chapters missing English translations
   - Supports both parenthetical format `"Original (English)"` and em-dash format `"Original — English"`

2. **Created fix script** (`scripts/fix-chapter-titles-english.ts`):
   - Uses predefined translations for known texts (Yi Zhou Shu, Zhuziyulei extra chapters)
   - Uses DeepSeek API to translate remaining Armenian chapter titles
   - Updates both processed JSON files AND database records

3. **Updated `parseChapterTitle()` function** in `src/lib/utils.ts`:
   - Now supports both parenthetical format and em-dash format
   - Em-dash format used by Armenian texts: `"Ադdelays — English"`

### Texts Fixed

| Text | Language | Chapters Fixed |
|------|----------|----------------|
| Samvel | Armenian | 41 |
| Kaitser (The Spark) | Armenian | 76 |
| Yashodhara Kaviyam | Tamil | 5 |
| Zhu Zi Yu Lei | Chinese | 74 (chapters 67-140) |
| Yi Zhou Shu | Chinese | 62 |
| **Total** | | **258 chapters** |

### Title Formats Used

- **Chinese**: `"克殷 (The Conquest of Yin)"` — parenthetical format
- **Armenian**: `" Delays. DELAYS — Family"` — em-dash format
- **Tamil**: `"இரண்டாவது சருக்கம் (Second Carukkam: The Peacock and the Dog)"` — parenthetical format

### Verification

Final audit shows:
- [grc] 11 texts, 442 chapters - ALL OK
- [hy] 6 texts, 195 chapters - ALL OK
- [it] 1 text, 66 chapters - ALL OK
- [la] 4 texts, 160 chapters - ALL OK
- [ta] 4 texts, 126 chapters - ALL OK
- [zh] 25 texts, 918 chapters - ALL OK

### Files Created/Modified

- `scripts/audit-chapter-titles.ts` — New audit script
- `scripts/fix-chapter-titles-english.ts` — New fix script
- `src/lib/utils.ts` — Updated `parseChapterTitle()` for em-dash format
- `data/chapter-title-audit.json` — Audit results (now empty = all fixed)

### Usage

To run audit: `pnpm tsx scripts/audit-chapter-titles.ts`
To fix issues: `pnpm tsx scripts/fix-chapter-titles-english.ts`

---

## 2026-01-25 Session: Armenian "Delays" Bug Fix — COMPLETE

**Agent**: a9fb74b
**Task**: Fix Armenian Unicode corruption where characters rendered as "delays"

### Root Cause
Armenian Unicode characters (U+0530-U+058F) were corrupted during development, with the word "delays" incorrectly substituted. This was NOT an encoding issue — raw source files in `data/raw/` are correct UTF-8. The corruption occurred only in code files, documentation, and some processed JSON files.

### Files Fixed

**Critical Code Files:**
- `scripts/seed-db.ts` — Fixed 13 corrupted Armenian entries (language displayName, author names, text titles)
- `src/server/translation/prompts.ts` — Fixed Armenian prompt examples

**Processing Scripts (6 files):**
- `scripts/process-anna-saroyan.ts`
- `scripts/process-khorhrdavor-miandznuhi.ts`
- `scripts/process-yerkir-nairi.ts`
- `scripts/process-samvel.ts`
- `scripts/process-arshagouhi-teotig.ts`
- `scripts/process-kaitser.ts`

**Regenerated JSON Files:**
- `data/processed/anna-saroyan/` (23 files)
- `data/processed/yerkir-nairi/` (25 files)
- `data/processed/khorhrdavor-miandznuhi/` (12 files)

### Fix Method
Used Python with Unicode codepoints (e.g., `chr(0x0540)`) to construct correct Armenian text, avoiding copy-paste corruption.

### Verification
- `grep -rn "delays" scripts/*.ts src/**/*.ts` → only legitimate uses (retry delays)
- `grep -c "delays" data/processed/*/*.json | grep -v ":0$"` → no results

### Documentation
Full report: `docs/armenian-delays-fix-report.md`

### Important for Future Armenian Work
- Always use Unicode escape sequences when adding Armenian text programmatically
- Raw files in `data/raw/` are correct — never modify them
- If Armenian displays as "delays", check processing scripts for corruption
- Unicode reference in `docs/armenian-delays-fix-report.md`

### Chapter Title Convention
Chapter titles in non-English texts should include an English translation in parentheses.
The website displays the original title with a grey English translation underneath.

**Format**: `"Original Title (English Translation)"` or just English if original is complex.

**Examples**:
- Chinese: `"理氣 (Principle and Vital Force)"`
- Armenian: `" Delays (Family)"`
- Greek: `"Περὶ τῆς ψυχῆς (On the Soul)"`

If chapter titles are only in the original language without English, users cannot navigate.
Audit agent (a2792fa) checking all texts for missing English translations.

---

### CRITICAL: Seed Script Workflow
The seed script (`pnpm db:seed`) is **IDEMPOTENT** — it SKIPS existing records.

This means:
- If you fix corrupted data in `seed-db.ts`, rerunning the seed will NOT update the database
- The old corrupted data remains in the database

**To update existing database records, you must:**
1. Write a fix script using SQL UPDATE statements (see `scripts/fix-armenian-db.ts`)
2. OR delete the records first, then reseed

**Example fix script usage:**
```bash
pnpm tsx scripts/fix-armenian-db.ts  # Fixes Armenian text corruption
```

This workflow issue caused the "delays" bug to persist on the live website even after
the seed-db.ts was fixed — the database still had the old corrupted data.

---

## 2026-01-25 Session: Featured Texts Reorganization — COMPLETE

**Agent**: ab470fa
**Task**: Reorganize text display to group by language with collapsible menus

### What Was Done
1. Installed Shadcn UI accordion component (`npx shadcn@latest add accordion`)
2. Updated `FeaturedTexts.tsx` to group texts by language in collapsible accordions
   - Languages sorted by descending text count (most prolific first)
   - Each language header shows "Display Name (N works)"
   - All accordions expanded by default
   - Texts within each language sortable by title/author
3. Updated home page sidebar (`src/app/page.tsx`) to sort languages by count
   - Shows count next to each language name
4. Updated `CategoryBrowser.tsx` (Browse page) with:
   - Languages sorted by descending text count
   - Tab labels show text count: "Chinese (15)"
   - Mobile-friendly horizontal scroll for tabs
5. Updated Browse page (`texts/page.tsx`) to sort languages by count

### Files Modified
- `/src/components/home/FeaturedTexts.tsx` — Complete rewrite with accordion grouping
- `/src/components/navigation/CategoryBrowser.tsx` — Added sorting + counts + mobile support
- `/src/app/page.tsx` — Language sidebar now sorted by count with count display
- `/src/app/(wiki)/texts/page.tsx` — Languages sorted by count
- `/src/components/ui/accordion.tsx` — New file (Shadcn component)

### Testing
- Type check: PASS
- Build: PASS
- Lint: PASS (no errors in modified files)

---

## 2026-01-24 Session: Raffi's Samvel Processing — COMPLETE

**Agent**: Samvel processor agent
**Task**: Process and translate Raffi's historical novel *Samvel*

### What Was Done
1. Examined raw text structure in `data/raw/samvel/` (41 files, 3 books)
2. Created `scripts/process-samvel.ts` processing script
3. Processed all 41 chapters into `data/processed/samvel/`
4. Verified Raffi already exists in seed-db.ts (from Kaitser agent)
5. Added Samvel text entry to seed-db.ts
6. Seeded database successfully (41 chapters)
7. Started translation via `translate-armenian.ts` (DeepSeek V3)
8. Created documentation: `docs/armenian-samvel-processing.md`

### Statistics
- 41 chapters across 3 books
- 4,138 paragraphs
- 946,703 characters (~1 MB)
- Average 101 paragraphs/chapter

### Book Structure
| Book | Chapters | Paragraphs | Characters |
|------|----------|------------|------------|
| Book 1 | 21 (Ch 1-21) | 1,540 | 337,757 |
| Book 2 | 14 (Ch 22-35) | 1,702 | 387,424 |
| Book 3 | 6 (Ch 36-41) | 896 | 221,522 |

### Historical Context
Set in 4th-century Armenia during conflict with Sasanian Persia:
- Christianity vs Zoroastrianism struggle
- Nerses the Great and the Mamikonian family
- One of Raffi's three major historical novels (with Khent and Davit Bek)

### Translation Status
IN PROGRESS — worker bdfd0dc running in background
- Chapters 1-2 done at time of note
- Using DeepSeek V3 (Gemini blocks Armenian historical violence content)

---

## 2026-01-24 Session: Anna Saroyan Processing — COMPLETE

**Agent**: a85a667 continuation
**Task**: Process and translate Perch Proshyan's epistolary novel "Anna Saroyan"

### What Was Done
1. Read and analyzed raw text (175 KB, 680 lines)
2. Discovered structure: 23 letters from September 1880 to October 1881
3. Implemented Armenian numeral parsing (Delays-Delays = 1-9, Delays = 10, Delays = 20, etc.)
4. Created `scripts/process-anna-saroyan.ts`
5. Processed to 23 JSON files in `data/processed/anna-saroyan/`
6. Added author (Perch Proshyan) and text entries to `seed-db.ts`
7. Seeded database successfully
8. Started translation via `translate-batch.ts` (DeepSeek V3)
9. Created documentation: `docs/armenian-anna-saroyan-processing.md`

### Statistics
- 23 letters/chapters
- 317 paragraphs
- 95,816 characters

### Issues Found
- Original text has numbering irregularities (two letters marked "15", jump from 22 to 24)
- `translate-armenian.ts` encountered max_tokens API errors; used `translate-batch.ts` instead

### Translation Status
IN PROGRESS — worker bd4d062 running in background

---

## 2026-01-25 (Session 20-21): Armenian Corpus Initiative — ACTIVE

### Overview
Launched comprehensive Armenian language support with 7 agents processing 6 texts (~5 MB total).
DeepSeek V3 used exclusively (Gemini blocks Armenian historical content).

### Active Agents Summary

| Agent | Task | Status | Notes |
|-------|------|--------|-------|
| a9cd5db | Kaitser (Raffi) ch 1-38 | Running | Processing + translating |
| a0a5d32 | Kaitser (Raffi) ch 39-76 | Running | Waiting for/using process script |
| a85a667 | Anna Saroyan | DONE ✓ | 23 letters, translation running (bd4d062) |
| a1babe9 | Arshagouhi Teotig | Running | 35 chapters, translation started |
| a28b9b8 | Khorhrdavor Miandznuhi | Running | 12-file diary format |
| afc0b52 | Yerkir Nairi | Running | 3-part novel |
| a773dc8 | Samvel (Raffi) | Running | 41 chapters, 3 books |
| a0a3adf | Translation Gap Fixer | Running | Finding/fixing all gaps across DB |
| a9fb74b | Armenian "Delays" Bug Fix | Running | Fixing character substitution issue |
| ab470fa | Featured Texts Reorganization | DONE | Grouping by language, collapsible, counts |
| a4fc5f0 | Pre-1900 → Pre-contemporary | DONE ✓ | Updated site descriptions |
| acf75d6 | Armenian Encoding Investigation | DONE ✓ | Found "delays" substitution issue |

### Key Findings This Session

1. **Gemini Content Filtering**: Gemini 2.5 Flash blocks 19th-century Armenian literature containing historical violence (PROHIBITED_CONTENT). DeepSeek V3 handles it appropriately.

2. **Sample Translation Quality**: Kaitser Chapter 1 received Grade A- from reviewer agent.

3. **Armenian Encoding Issue**: The word "delays" was substituted for Armenian characters in code/docs. Raw source files are correct. See `docs/armenian-encoding-investigation.md`.

4. **Site Terminology Update**: Changed "pre-1900" to "pre-contemporary" to include early 20th-century texts (1909 massacre memoir).

5. **DeepSeek max_tokens**: Fixed translate-armenian.ts to use 8192 (DeepSeek's actual limit) instead of 16384.

### Files Created/Modified This Session

**New Scripts:**
- `scripts/translate-armenian.ts` — DeepSeek-based Armenian translator
- `scripts/process-arshagouhi-teotig.ts` — Massacre memoir processor
- `scripts/process-anna-saroyan.ts` — Epistolary novel processor (by agent)
- Additional processing scripts created by agents

**New Documentation:**
- `docs/armenian-translation-observations.md` — Workflow documentation
- `docs/armenian-encoding-investigation.md` — Encoding issue analysis
- `docs/armenian-arshagouhi-teotig-processing.md` — Text-specific docs
- `docs/translation-gaps-audit.md` — Gap finder report (in progress)

**Database:**
- Added language: Armenian (hy, ID: 7)
- Added authors: Raffi, Perch Proshyan, Arshagouhi Teotig (more by agents)
- Added texts: Being seeded by agents

---

## 2026-01-25 (Session 21): Arshagouhi Teotig Processing Complete

### Arshagouhi Teotig — Adana's Wounds and Orphans

**Status:** Processing complete, translation in progress

**Text:** Eyewitness memoir of the 1909 Adana massacre
**Author:** Arshagouhi Teotig (1875–1960s)
**Language:** Western Armenian
**Chapters:** 35
**Total paragraphs:** 743

### Work Completed

1. **Processing script created:** `scripts/process-arshagouhi-teotig.ts`
   - Text structure: Each line = one paragraph (no blank line separators)
   - Chapter headers in ALL CAPS Armenian
   - Optional date line after chapter title
   - Section breaks marked by standalone `*`
   - Output: 35 JSON files in `data/processed/arshagouhi-teotig/`

2. **Database seeding:**
   - Author entry added: `arshagouhi-teotig` (Armenian feminist writer)
   - Text entry added: "Adana's Wounds and Orphans" (hy language, arshagouhi-teotig slug)
   - 35 chapters successfully seeded

3. **Translation started:**
   - Worker `bbbc6be` running with DeepSeek V3
   - Fixed max_tokens issue (16384 → 8192 for DeepSeek limit)
   - Progress: Chapters 1-9 done at time of note

4. **Documentation written:**
   - `docs/armenian-arshagouhi-teotig-processing.md` created
   - Includes: historical context, author bio, journey itinerary, chapter list, processing notes

### Bug Fix: max_tokens in translate-armenian.ts

DeepSeek V3's max_tokens limit is 8192, not 16384. Changed line 199:
```typescript
max_tokens: 8192,  // was 16384
```

### Historical Context

The 1909 Adana massacre killed over 20,000 Armenians. Arshagouhi Teotig traveled to Cilicia in October-November 1909 as a relief worker. Her memoir documents:
- Aftermath of the massacres
- Orphanages in Mersin and Adana
- Refugee conditions in various towns
- Personal encounters with survivors

This is one of the few female-authored primary sources for these events.

---

## 2026-01-25 (Session 20): Armenian Translation Review Complete

### Translation Review Results
- **Agent** a740e5e completed quality review of Kaitser Chapter 1 translation
- **Grade**: A- (high quality, suitable for publication)
- **Strengths**:
  - Excellent accuracy in capturing meaning
  - Literary voice and melancholic tone preserved
  - All proper names correctly transliterated (Shushan, Nigyar, Farhat, Sahak)
  - Cultural terms appropriately retained (ferrashes, shahis, arak)
  - Historical sensitivity maintained for persecution content
- **Weaknesses** (minor):
  - Occasional stilted phrasing ("foolish-filled past")
  - One formatting artifact with ellipses within words
- **Recommendation**: Proceed with full Armenian corpus using DeepSeek V3

### Critical Finding Confirmed
- Gemini 2.5 Flash BLOCKED kaitser translation with PROHIBITED_CONTENT
- Reason: Historical violence (tax collector torture, slavery threats)
- DeepSeek V3 translated successfully with high quality
- **Decision**: Use DeepSeek for ALL Armenian texts

### Files Produced
- `data/armenian-sample-review/translation-review.md` — detailed quality review

### Armenian Translator Fixed
- `scripts/translate-armenian.ts` was using Gemini (would fail due to content filtering)
- Updated to use DeepSeek V3 via `getTranslationClient()` from `client.ts`
- Now consistent with sample translation that received A- grade

### Armenian 7-Agent Pipeline Launched
7 parallel agents for full Armenian corpus (6 texts):

| Agent | Text | Author | Chapters | Task |
|-------|------|--------|----------|------|
| a9cd5db | Kaitser | Raffi | 1-38 | Create process script, seed, translate |
| a0a5d32 | Kaitser | Raffi | 39-76 | Wait for process script, then seed + translate |
| a85a667 | Anna Saroyan | Perch Proshyan | All | Examine, process, seed, translate |
| a1babe9 | Arshagouhi Teotig memoir | Arshagouhi Teotig | All | Examine, process, seed, translate |
| a28b9b8 | Khorhrdavor Miandznuhi | TBD | 12 files | Examine diary format, process, translate |
| afc0b52 | Yerkir Nairi | TBD | 5 files | Examine 3-part novel, process, translate |
| a773dc8 | Samvel | Raffi | 41 ch | Historical novel (4th-c. Armenia), process, translate |

**Workflow per agent:**
1. Read raw text, understand structure
2. Create `scripts/process-<name>.ts`
3. Add author + text to `seed-db.ts`
4. Run processing → seeding → `translate-armenian.ts`
5. Document in `docs/armenian-<name>-processing.md`

**Note on Gemini blocking:**
Gemini 2.5 Flash blocks 19th-century Armenian literature containing historical violence
(tax collector torture, massacre accounts). This is disappointing for foundational works
like Raffi's Kaytser. DeepSeek V3 handles this content appropriately and received A- grade.

### Rizhilu Translation Progress
- 4 workers running; Worker 3 currently on chapter 23
- Estimated completion: within next few hours

### Documentation Updated
- CLAUDE.md: Added Armenian Initiative section, updated session date, added to Remaining Work
- This file: Added Session 20 entry

### Next Steps for Armenian
1. Create processing scripts: `process-kaitser.ts`, `process-anna-saroyan.ts`, `process-arshagouhi-teotig.ts`
2. Add authors to seed-db.ts: Raffi, Perch Proshyan, Arshagouhi Teotig
3. Add text entries to seed-db.ts with language `hy`
4. Create `scripts/translate-armenian-deepseek.ts` (based on translate-batch.ts)
5. Run full translation pipeline

---

## 2026-01-24: Armenian Language Support Added

### Changes
- Added Armenian language to database: code=`hy`, name=`Armenian`, displayName=`Հdelays` (Hayeren)
- Added `hy` to LANGUAGE_FONTS in ParagraphPair.tsx for serif font styling

### Database State
7 languages now in `languages` table: Armenian, Classical Chinese, English, Greek, Italian, Latin, Tamil

### Website Integration Verification
- CategoryBrowser.tsx: Languages passed as prop from parent, dynamically rendered as tabs
- BrowsePage (/texts): Queries `trpc.texts.list()`, groups by language — Armenian tab will appear when texts exist
- SearchClient.tsx: Language filter from `trpc.search.languages()` — uses INNER JOIN with texts, so only shows languages with texts
- FeaturedTexts.tsx: Uses language.code from text data — works for any language
- InterlinearViewer + ParagraphPair: Added hy to LANGUAGE_FONTS for serif font

### Notes
- Armenian script uses unique characters (Unicode range U+0530-U+058F)
- Geist font (default) doesn't include Armenian glyphs — browser falls back to system fonts
- System font fallback works well for Armenian on most platforms
- No additional Google Fonts needed — serif fallback is sufficient

---

## 2026-01-24: Rizhilu (日知錄) — Complete Pipeline

### Text Information
- **Title**: 日知錄 (Rizhilu) — "Record of Daily Knowledge"
- **Author**: Gu Yanwu (顧炎武, 1613-1682), early Qing dynasty scholar
- **Genre**: Scholarly miscellany (筆記) — philology, history, geography, government, ethics
- **Source**: Project Gutenberg eBook #25262 (~1.5 MB, 16,880 lines, simplified Chinese)

### Processing Results
- **Volumes**: 32 (all present, ●卷一 through ●卷三十二)
- **Sections**: 1,010 (marked with ○ symbol)
- **Total characters**: 498,926
- **Chapter structure**: One chapter per volume (32 chapters)
- **Preface**: Included as first paragraph of Chapter 1

### Key Issues Resolved
1. Line 15223 had volume marker inline with previous text — handled by splitting at ●卷
2. Project Gutenberg header/footer stripped cleanly
3. Text uses simplified Chinese (preserved as-is)

### Files Created
- `scripts/process-rizhilu.ts` — Processing script
- `data/processed/rizhilu/chapter-001.json` through `chapter-032.json`
- `docs/rizhilu-processing.md` — Full documentation

### Database Seeding
- Author: `gu-yanwu` (slug) added to seed-db.ts
- Text: `rizhilu` (slug) added to seed-db.ts
- Seeded successfully: 32 chapters confirmed in database

### Translation Workers (Started 2026-01-24)
4 parallel workers with 5000ms delay between chapters:
- Worker 1: chapters 1-8
- Worker 2: chapters 9-16
- Worker 3: chapters 17-24
- Worker 4: chapters 25-32

Logs at: /tmp/rizhilu-worker{1,2,3,4}.log

---

## 2026-01-24: Diarium Urbis Romae — Paragraph Segmentation Fix

### Problem
The Diarium chapters had poor paragraph breaks caused by:
1. OCR from a critical edition with two-column layout (main text + apparatus)
2. Footnote apparatus (manuscript sigla, variant readings, bibliography) interleaved INTO main text
3. Hyphenation artifacts from line breaks in the original OCR

### Solution Implemented
Rewrote `scripts/process-diarium.ts` with:
1. **Apparatus stripping**: Patterns to detect and remove scholarly apparatus lines
2. **Inline apparatus cleaning**: Remove embedded sigla and references
3. **Hyphenation rejoining**: Fix words split across lines
4. **Content-aware paragraph detection**: Use diary entry patterns (dates, year markers) for breaks

### Results
- Raw lines: 7,252
- After cleaning: 5,934 lines (1,318 apparatus lines removed)
- Chapters: 66 (65 main + 1 appendix)
- Total paragraphs: 208

### Limitation
Some apparatus remains embedded mid-sentence due to two-column OCR interleaving.
This is impossible to fix programmatically without the original clean text.
The translation model should handle the noise acceptably.

### Files Modified
- `scripts/process-diarium.ts` - Major rewrite with apparatus detection
- `data/processed/diarium-urbis-romae/chapter-*.json` - All 66 chapters regenerated
- Database reseeded (Neon project bitter-tooth-04461121)

### Documentation
Full analysis in `docs/diarium/paragraph-fix.md`

---

## 2026-01-24: Shisan Jing Zhushu (十三經註疏) — Processing Plan (Session 16)

### Corpus Overview
The Thirteen Classics with Commentaries — the complete set of canonical Confucian texts with
multi-layered Tang dynasty orthodox commentaries (正義) and sub-commentaries (註疏).
Location: `data/raw/Shisan_Jing_Zhushu/`
Index: `data/raw/Shisan_Jing_Zhushu/13_books_index.txt` (752 lines)

### Texts to Process (13 active, 1 empty)

| # | Chinese | English | Slug | Chapters | Commentator |
|---|---------|---------|------|----------|-------------|
| 1 | 論語註疏 | Analects with Commentary | lunyu-zhushu | 21 | He Yan + Xing Bing |
| 2 | 孟子註疏 | Mencius with Commentary | mengzi-zhushu | 15 | Zhao Qi + Sun Shi |
| 3 | 孝經註疏 | Classic of Filial Piety with Commentary | xiaojing-zhushu | 10 | Xing Bing |
| 4 | 爾雅註疏 | Erya Dictionary with Commentary | erya-zhushu | 11 | Guo Pu + Xing Bing |
| 5 | 周易正義 | Book of Changes with Commentary | zhouyi-zhengyi | ~102 | Kong Yingda |
| 6 | 尚書正義 | Book of Documents with Commentary | shangshu-zhengyi | 22 | Kong Yingda |
| 7 | 周禮註疏 | Rites of Zhou with Commentary | zhouli-zhushu | 44 | Zheng Xuan + Jia Gongyan |
| 8 | 儀禮註疏 | Ceremonial Rites with Commentary | yili-zhushu | 51 | Zheng Xuan + Jia Gongyan |
| 9 | 禮記正義 | Book of Rites with Commentary | liji-zhengyi | 56 | Kong Yingda |
| 10 | 禮記註疏 | Book of Rites — Selected Chapters | liji-zhushu | 29 | Zheng Xuan + Kong Yingda |
| 11 | 春秋左傳正義 | Zuo Commentary on Spring and Autumn | zuozhuan-zhengyi | 37 | Kong Yingda |
| 12 | 春秋公羊傳註疏 | Gongyang Commentary on Spring and Autumn | gongyang-zhushu | 30 | He Xiu + Xu Yan |
| 13 | 春秋穀梁傳註疏 | Guliang Commentary on Spring and Autumn | guliang-zhushu | 21 | Fan Ning + Yang Shixun |
| — | 毛詩正義 | (EMPTY — skip) | — | 0 | — |

**Total: ~449 chapters across 13 texts**

### 4-Agent Division

**Agent 1: Four Books + Small Classics** (~57 chapters)
- 論語註疏 (21), 孟子註疏 (15), 孝經註疏 (10), 爾雅註疏 (11)

**Agent 2: Changes + Documents** (~124 chapters)
- 周易正義 (102), 尚書正義 (22)

**Agent 3: Three Rites** (~180 chapters)
- 周禮註疏 (44), 儀禮註疏 (51), 禮記正義 (56), 禮記註疏 (29)

**Agent 4: Spring and Autumn Commentaries** (~88 chapters)
- 春秋左傳正義 (37), 春秋公羊傳註疏 (30), 春秋穀梁傳註疏 (21)

### Text Format Notes
- Multi-layered: base text + （glosses） + [疏] sub-commentary + 【scholar】 attributions
- One .txt file = one chapter (volume/卷)
- Paragraphs: split on [疏] boundaries and natural textual breaks
- Header lines like "原文(無註)" should be stripped
- ALL commentary layers are preserved (they ARE the text in a 註疏 edition)
- Index cross-references (bare book names) are navigation links, NOT content

### Status (updated 2026-01-24, session 17 checkpoint)

**All 13 texts processed and seeded to DB. Translation in progress.**

- Agent 1 (a9f1c24 — Four Books + Small Classics): AGENT DONE, translation workers running
  - Script: `scripts/process-shisan-jing-1.ts`
  - Texts: lunyu-zhushu (21), mengzi-zhushu (15), xiaojing-zhushu (10), erya-zhushu (11) = 57 chapters
  - Translation workers: lunyu (1-11, 12-21), mengzi (1-15), xiaojing (2-10), erya (1-11)
  - Last known progress: xiaojing 9/10, erya 3/11, lunyu ~9/21, mengzi 2/15

- Agent 2 (ace30af — Changes + Documents): AGENT DONE, translation workers running
  - Script: `scripts/process-shisan-jing-2.ts`
  - Texts: zhouyi-zhengyi (104), shangshu-zhengyi (22) = 126 chapters
  - Author added: Kong Yingda (kong-yingda)
  - Translation workers: babf3aa (zhouyi 1-52), b6a0f7d (zhouyi 53-104), ba80c30 (shangshu 1-22)

- Agent 3 (a86e80d — Three Rites): SEEDED, translating
  - Script: `scripts/process-shisan-jing-3.ts`
  - Texts: zhouli-zhushu (42), yili-zhushu (51), liji-zhengyi (56), liji-zhushu (29) = 178 chapters
  - Authors added: Jia Gongyan (jia-gongyan), Zheng Xuan Liji ed. (zheng-xuan-liji)
  - DB status: 2/178 translated (liji-zhengyi 2)
  - Translation workers: bfc83a7 (zhouli), b4c8f59 (yili), b332ac1 (liji-zy), b0508ee (liji-zs)
  - Key decision: 周禮.txt (6 lines, TOC only) excluded; only 42 actual volumes processed

- Agent 4 (ace6429 — Spring and Autumn): AGENT DONE, 6 translation workers running
  - Script: `scripts/process-shisan-jing-4.ts`
  - Texts: zuozhuan-zhengyi (43), gongyang-zhushu (30), guliang-zhushu (21) = 94 chapters
  - Paragraph stats: zuozhuan avg 94/ch, gongyang avg 101/ch, guliang avg 81/ch
  - Translation workers: bc593fa (zuozhuan 1-15), bc3b540 (zuozhuan 16-30), b9c848d (zuozhuan 31-43),
    bce1f8a (gongyang 1-15), b624f79 (gongyang 16-30), bdcaaab (guliang 1-21)

**Kongzi Jiayu: 80/80 COMPLETE** (agent a6fde9f finished)
**Eustathius Odyssey: 10/27 translated** (agents ab5dae1, a4043fb, afff370 still running)

### Reinforcement Translation Agents (launched session 17)
4 additional agents to accelerate translation:
- Agent A (a7e1ecc): yili-zhushu (1-25, 26-51) + erya-zhushu (1-11)
- Agent B (aca4e1f): zhouli-zhushu (1-21, 22-42) + xiaojing-zhushu (1-10)
- Agent C (a3bb94a): liji-zhengyi (1-28, 29-56) + liji-zhushu (1-29)
- Agent D (a541e9f): lunyu-zhushu (1-21) + mengzi-zhushu (1-15) + shangshu-zhengyi (1-22)
All use --delay 2000, skip logic prevents duplication with existing workers.

---

## 2026-01-24: Hesiod Theogony Exegesis Regrouping (Session 15)

### Task: Merge 109 individual sections into 13 thematic chapters

**Problem:** The "Exegesis on Hesiod's Theogony" had 109 "chapters" in the database,
each corresponding to commentary on a single line number of the Theogony (e.g.,
"Section 134", "Section 319b"). This was excessive for the table of contents.

**Solution:** Created `scripts/regroup-hesiod-exegesis.ts` that:
1. Reads all 109 chapter JSONs
2. Extracts the Hesiod line number from each title
3. Groups them into 13 thematic chapters matching the Theogony's structure
4. Merges paragraphs within each group, re-indexing sequentially
5. Writes new chapter files and deletes leftovers

**New chapter structure (13 chapters):**
1. Commentary on the Proem: Invocation of the Muses (Lines 1-115) - 8 paragraphs
2. Commentary on the Cosmogony: Chaos, Gaia, Tartarus, Eros (Lines 116-153) - 4 paragraphs
3. Commentary on the Castration of Uranus (Lines 154-210) - 15 paragraphs
4. Commentary on the Children of Night (Lines 211-232) - 4 paragraphs
5. Commentary on the Sea Deities: Nereus, Thaumas, Phorcys (Lines 233-269) - 7 paragraphs
6. Commentary on Sea Monsters and the Gorgons (Lines 270-336) - 15 paragraphs
7. Commentary on the Rivers, Oceanids, and Titans (Lines 337-452) - 8 paragraphs
8. Commentary on the Birth and Rise of Zeus (Lines 453-506) - 10 paragraphs
9. Commentary on Prometheus and the Theft of Fire (Lines 507-616) - 11 paragraphs
10. Commentary on the Titanomachy (Lines 617-735) - 9 paragraphs
11. Commentary on Tartarus (Lines 736-819) - 6 paragraphs
12. Commentary on the Typhonomachy (Lines 820-880) - 3 paragraphs
13. Commentary on the Marriages of Zeus (Lines 881-929) - 10 paragraphs

**Total paragraphs preserved: 110 (same as original 109 chapters)**

**Database operations:**
- Ran `scripts/reset-hesiod-chapters.ts` to delete 109 old chapters + 109 translations
- Ran `scripts/seed-db.ts` to insert 13 new merged chapters
- Ran `scripts/translate-batch.ts --text hesiod-theogony-exegesis --start 1 --end 13`
- Result: 13/13 chapters translated, 0 errors

**Files created:**
- `scripts/regroup-hesiod-exegesis.ts` - the regrouping script
- `scripts/reset-hesiod-chapters.ts` - DB cleanup script

---

## 2026-01-24: Translation Gap Check & Continuation (Session 14)

### Gap Check Results (verified via Neon DB queries):

**Greek XML R2 Texts — ALL COMPLETE, NO GAPS:**
- hesiod-theogony-exegesis: 109/109 chapters translated, all paragraphs match source counts
- periplus-maris-exteri: 31/31 chapters translated, all paragraphs match
- periplus-maris-interni: 6/6 chapters translated, all paragraphs match
- artemidori-geographia: 3/3 chapters translated, all paragraphs match

**Eustathius Odyssey (slug: `eustathius-odyssey`, NOT `eustathius-odyssey-commentary`):**
- Chapter 0: 23/23 paragraphs — OK
- Chapter 17: 222/222 paragraphs — OK
- Chapter 18: 197/197 paragraphs — OK
- Chapters 1-16, 19-24: NOT TRANSLATED (22 chapters missing, ~5,300 paragraphs)
- ISSUE: Previous session's translation agents used wrong slug (`eustathius-odyssey-commentary`)
  and thus never found the text. Agents killed and relaunched with correct slug.
- New agents: 3 workers with correct slug `eustathius-odyssey` (ch 1-8, 9-16, 19-24)

**Kongzi Jiayu — NEW TEXT (agent a6fde9f):**
- Processing from `data/raw/kongzi_jiayu/` (10 volumes, Classical Chinese)
- Agent examining, parsing, seeding, and translating

**Hesiod continuation (agent a0f8f84):** Already complete — all 109 chapters were translated
**Marcianus continuation (agent a04628c):** Already complete — all 40 chapters translated

---

## 2026-01-24: Progress Check (Session Resume)

### Translation Status (DB counts)
- **Carmina Graeca**: 21/21 COMPLETE
- **Diognetum**: 12/12 COMPLETE
- **Historia Nova**: 287/287 COMPLETE (zero errors)
  - Final worker completed remaining 164 chapters (2026-01-24)
  - Log: docs/translation-log-historia-nova.md
- **Sophistici Elenchi**: 35/35 COMPLETE (agent af2cefd, zero errors)
- **Tongjian**: 42/45 translated (~93%) — 2 workers running (b76003b, b83ad01)

### Eustathius Odyssey Commentary — Volume 2 PROCESSING COMPLETE
- **Volume 2 Processor (a44a6b7)**: DONE — all 13 chapters (12-24) produced
  - Modified: book-splitter.ts, content-classifier.ts (interline noise), process-eustathius.ts (--volume flag)
  - Quality: 2,589 paragraphs, 1,424,824 chars, 94.7-97.4% Greek, 1,151 digits (OCR confusion), 7 verse refs
- **Volume 2 Reviewer (a20bfed)**: IN PROGRESS — checking digit counts, verse refs across ch 12-24
- **Combined totals**: 25 chapters, 6,146 paragraphs, 3,318,446 characters
- **All 25 raw .txt + 25 processed .json files exist** in data/raw/ and data/processed/
- **Reviewer sign-off**: SATISFIED (B+ both volumes, production-ready)
- **Seeded to DB**: 25 chapters inserted (author: Eustathius of Thessalonica, slug: eustathius-odyssey)
- **Translation workers launched** (3 parallel agents, DeepSeek, grc, 6000 chars/batch, 3s delay):
  - Agent a58c5f4: chapters 0-8 (preface + Books 1-8)
  - Agent aa2274c: chapters 9-16
  - Agent a05fbf7: chapters 17-24
- **User instruction fulfilled**: "When the raw files for the commentary on the Odyssey are complete and clean and ready, enqueue the text for parsing, careful consideration and reading, and translation on the website."

## 2026-01-24: Greek XML R2 Pipeline — Dual-Agent (NEW)

- **New texts to process**:
  - tlg3156.tlg001: "Exegesis in Hesiodi Theogoniam" (anonymous, 1,644 lines)
  - tlg4003.tlg001: "Periplus Maris Exteri" (Marcianus of Heraclea, 1,355 lines)
  - tlg4003.tlg002: "Menippi Periplus Maris Interni" (Marcianus, 523 lines)
  - tlg4003.tlg003: "Artemidori Geographia" (Marcianus, 317 lines)
- **Pipeline**: Dual-agent (Parser a46da65 + Reviewer ae6bd83)
- **Joint doc**: docs/greek-xml-r2-collaboration.md
- **Decision**: Treat Marcianus's 3 works as 3 separate texts (each small enough)
- **Workflow formalized**: Added "Workflow G: Dual-Agent Quality Pipeline" to CLAUDE.md and reference-guide.txt
- **When complete**: Add to seed-db.ts, seed DB, launch translation workers

## 2026-01-24: Eustathius Pipeline — COMPLETE (Reviewer Approved + Seeded + Translating)

- **Reviewer (a20bfed) sign-off**: SATISFIED — Volume 2 Grade B+ (matching Volume 1)
- **Volume 2 metrics**: 13 chapters, 2,589 paragraphs, 1.4M chars, 94.7-97.4% Greek
- **Combined**: 25 chapters, 6,146 paragraphs, 3.3M characters
- **Seeded to DB**: 25 chapters inserted successfully
- **Translation workers launched** (3 parallel, DeepSeek grc, 6000 chars/batch):
  - a58c5f4: chapters 0-8
  - aa2274c: chapters 9-16
  - a05fbf7: chapters 17-24
- **User instruction fulfilled**: auto-enqueue when ready

## 2026-01-24: Greek XML Texts — SEEDED + Translation Workers Launched

- **Seeding complete**: 3 new authors + 3 new texts added to seed-db.ts and seeded into DB
  - Epistle to Diognetus: 12 chapters inserted (author: "Anonymous (Diognetus)", slug: diognetus-author)
  - New History (Historia Nova): 287 chapters inserted (author: "Zosimus", slug: zosimus)
  - Paraphrase on Sophistical Refutations: 35 chapters inserted (author: "Anonymous (Aristotelian commentator)", slug: soph-elenchi-paraphrast)
- **Translation workers launched** (3 parallel agents via DeepSeek):
  - Agent affd974: Diognetum (12 chapters)
  - Agent a21b76e: Historia Nova (287 chapters)
  - Agent af2cefd: Sophistici Elenchi Paraphrasis (35 chapters)
- **Greek XML pipeline: COMPLETE** — Parser (A) → Reviewer (A) → Seed → Translate

## 2026-01-24: Eustathius Odyssey — Round 2 Dual-Agent Pipeline

- **Round 2 Processor** (agent aa6a9f5): Fixed all 5 Round 1 issues; now processing Volume 2
- **Round 2 Reviewer** (agent acf68b7): Volume 1 grade: **B+** (translatable); awaiting Volume 2
- **Volume 1 status**: B+ — digits reduced 60%, verse refs 99.6% stripped, boundaries fixed
- **Volume 2 status**: NOT YET PROCESSED — critical blocker for overall Grade A
- **Reviewer's remaining requests**:
  1. Process Volume 2 (Books 12-24) with same pipeline
  2. Strip 6 remaining apparatus garble paragraphs (minor)
  3. Strip 19 remaining verse refs (extremely garbled forms, 0.5% paragraphs)
- **Round 2 documentation**:
  - Joint: `docs/eustathius-r2-collaboration.md`
  - Reviewer scratch: `docs/eustathius-r2-reviewer-scratchpad.md`
  - Processor scratch: `docs/eustathius-processor-scratchpad.md`
- **Volume 1 source**: `data/difficult_extra_processing/commentariiadhom01eust_djvu.txt`
- **Volume 2 source**: `data/difficult_extra_processing/commentariiadhom02eust_djvu.txt`
- **Volume 2 agents launched**:
  - Processor: agent a44a6b7 (extends pipeline for Vol 2, Books 12-24)
  - Reviewer: agent a20bfed (reviews Vol 2 output, waits for Processor)
- **When both volumes Grade A**: Auto-seed DB + translate via DeepSeek

## 2026-01-24: Greek XML Translation Workers — Status

- **Diognetum** (agent affd974): COMPLETE — 12/12 chapters, 100 paragraphs, 0 errors
- **Historia Nova** (3 parallel workers):
  - Agent a21b76e: chapters 1-128 (Books 1-2)
  - Agent a9d67d7: chapters 129-223 (Books 3-4)
  - Agent a63aef9: chapters 224-287 (Books 5-6)
- **Sophistici Elenchi** (agent af2cefd): IN PROGRESS — 35 chapters

## 2026-01-24: Greek XML Reviewer Agent -- Output Review

- **Task**: Review all output from the Greek XML TEI Parser Agent (a95b70a)
- **Files reviewed**: 334 chapter JSON files + 334 raw text files across 3 texts
- **Verdict**: GRADE A overall. Zero parser bugs. All issues are source-XML artifacts.
- **Texts approved for pipeline**:
  - Diognetum (12 chapters, A-)
  - Historia Nova (287 chapters, A)
  - Sophistici Elenchi Paraphrasis (35 chapters, B+)
- **Critique written to**: `docs/greek-xml-collaboration.md`
- **Working notes at**: `docs/greek-xml-reviewer-scratchpad.md`
- **Next steps**: ~~Seed into DB + launch translation workers~~ DONE (see above)

---

## Research Summary

### Tech Stack Confirmed
- Next.js 15+ (App Router, Turbopack) — `npx create-next-app@latest --typescript --tailwind --eslint --app --src-dir`
- tRPC v11 with @trpc/tanstack-react-query — fetch adapter for App Router API routes
- Drizzle ORM — relations v1 API (stable), v2 in beta
- NextAuth.js v5 (Auth.js) — credentials provider + OAuth, JWT strategy
- Shadcn UI — `npx shadcn@latest init` then add components as needed
- Vitest + @testing-library/react — jsdom environment, vite-tsconfig-paths
- PostgreSQL — Neon (free tier: 0.5GB, 190 compute hours) or local Docker

### Key Technical Decisions

1. **Package manager:** pnpm recommended (better shadcn compatibility with React 19)
2. **tRPC v11 pattern:**
   - /trpc folder with init.ts, router.ts, client.tsx, server.tsx
   - fetchRequestHandler at /api/trpc/[trpc]/route.ts
   - createCaller for server components (no HTTP overhead)
   - prefetch + HydrateClient for streaming
3. **Auth pattern:**
   - auth.config.ts (providers) + auth.ts (adapter + session strategy)
   - app/api/auth/[...nextauth]/route.ts exports { GET, POST }
   - JWT strategy (no database session table needed initially)
   - Middleware for route protection
4. **Drizzle pattern:**
   - pgTable definitions with explicit column types
   - relations() for ORM-level relationships
   - .references() for FK constraints
   - drizzle-kit for migrations (drizzle.config.ts)
5. **Testing:**
   - Vitest + jsdom for unit/component tests
   - Playwright for E2E (async server components can't be tested with Vitest)
   - vitest.config.mts at root

### Source Text Details

**Zhu Zi Yu Lei (朱子語類)**
- 140 chapters (juan/卷)
- URN: ctp:zhuzi-yulei
- Individual chapters: ctp:zhuzi-yulei/1 through /140
- Each chapter returns `fulltext` (ordered paragraph list)
- Topics: metaphysics, learning, Four Books commentary, classics, history, misc
- API requires authentication for subsections enumeration
- Python `ctext` package available, or raw JSON API calls

**De Ceremoniis**
- 2 books, ~180+ chapters total
- Internet Archive: archive.org/details/bub_gb_OFpFAAAAYAAJ (Reiske edition)
- Greek text + Latin translation in same edition
- OCR quality varies — polytonic Greek diacritics are problematic
- Princeton Byzantine Translations may have partial cleaner text
- Moffatt/Tall 2012 English translation is under copyright — cannot use
- Need AI-generated English translation from the Greek

### Data Model Notes

Content storage: JSON column with paragraph arrays
- Source: { paragraphs: [{ index: 0, text: "..." }, ...] }
- Translation mirrors with matching indices
- This enables paragraph-aligned rendering in InterlinearViewer
- For Chinese: each "paragraph" might be a single statement or exchange
- For Greek: each "paragraph" might be a section or stanza

Versioning:
- TranslationVersion is append-only
- Each version stores full content (not diffs) — simplifies reading, costs more storage
- Diffs computed on-the-fly for display using a library like `diff` or `jsdiff`
- currentVersionId on Translation points to latest

Endorsements:
- One per user per version (unique constraint)
- Count aggregated for display
- Version with most endorsements = "community preferred"

### Interlinear Viewer Design Notes

Core concept: CSS Grid or Flexbox table with two columns
- Each row = one ParagraphPair component
- Left cell: source text (potentially with original script font)
- Right cell: translation text
- Rows auto-height to tallest cell (natural CSS grid behaviour)
- Synchronized scroll NOT needed if using row-based alignment
- Mobile: stack vertically (source above, translation below)
- Font considerations:
  - Chinese: Noto Serif CJK or Source Han Serif
  - Greek: Noto Serif with polytonic support
  - Latin: any good serif
  - English translation: system font stack or Inter

### Deployment Architecture

MVP path (Vercel + Neon):
- Vercel Hobby (free) handles Next.js deployment
- Neon free tier for PostgreSQL
- Vercel automatically builds on git push
- Environment variables in Vercel dashboard
- Custom domain via Vercel DNS or external registrar

Production path (self-hosted):
- Docker Compose: Next.js container + PostgreSQL container
- Caddy or nginx as reverse proxy with auto-SSL
- VPS: Hetzner CAX11 (€3.79/mo, ARM) or DigitalOcean $6/mo
- Backups: pg_dump cron to object storage

### Implementation Order (Dependencies)

Phase 1 must come first: schema, auth, Docker compose
Phase 2 can parallel with Phase 3 partially
Phase 3 depends on seeded data (Phase 2)
Phase 4 depends on Phase 3 (reading UI exists)
Phase 5 depends on Phase 4 (versions exist to endorse)
Phase 6 can happen any time after Phase 2
Phase 7 can happen after Phase 3
Phase 8 can happen after Phase 1 (deploy empty, then iterate)

Actually, earliest useful deployment is after Phase 3 — reading works.

### Risks and Mitigations

1. ctext.org rate limits / auth requirements
   - Mitigation: create account, cache aggressively, store raw in data/raw/
   - Fallback: manually download chapter pages and parse HTML

2. OCR quality of De Ceremoniis
   - Mitigation: Princeton Byzantine Translations for partial clean text
   - Mitigation: AI-assisted cleanup of OCR output
   - Mitigation: start with a few chapters, iterate

3. Paragraph alignment between source and translation
   - Mitigation: editor enforces paragraph count matching
   - Mitigation: allow "empty" paragraphs for padding

4. Polytonic Greek rendering
   - Mitigation: test with Noto Serif early, specify @font-face
   - Mitigation: Unicode normalization (NFC) on input

5. Scale of Zhu Zi Yu Lei (140 chapters, potentially thousands of paragraphs)
   - Mitigation: paginate by chapter (already planned)
   - Mitigation: lazy-load translation versions

### Translation API Observations (Session 2)

**DeepSeek R1 (deepseek-reasoner):**
- Very slow — each batch takes 30-60+ seconds due to chain-of-thought reasoning
- Unnecessary for translation (reasoning overhead provides no benefit)
- 64K max output — would eliminate batching need, but too slow to be practical
- Sometimes returns string indices instead of numbers (needed coercion fix)

**DeepSeek V3.2 (deepseek-chat):**
- Much faster — responses in seconds
- 8K max output (hard limit enforced by API: "valid range is [1, 8192]")
- Requires paragraph batching for large chapters
- $0.28/M input, $0.42/M output — extremely cheap

**Batching strategy:**
- MAX_CHARS_PER_BATCH = 8000 source chars per batch
- With 8K output tokens (~32K chars), 8000 source chars translates comfortably within limit
- ZZYL chapters: 66-100+ paragraphs, short each (classical Chinese) — usually 1-3 batches
- De Ceremoniis chapters: 2-68 paragraphs, VERY long each (Greek) — needs 5-19 batches
- Chapter paragraph/char sizes:
  - Ceremonialis ch1: 2 para, 2K chars
  - Ceremonialis ch2: 68 para, 150K chars (largest!)
  - Ceremonialis ch3: 9 para, 41K chars → 7 batches
  - Ceremonialis ch4: 9 para, 54K chars
  - Ceremonialis ch5: 7 para, 39K chars
  - Ceremonialis ch6: 6 para, 46K chars
  - Ceremonialis ch7: 16 para, 122K chars

**Translation status (current session):**
- ZZYL ch1: DONE (66 paragraphs, DeepSeek R1)
- ZZYL ch2: DONE (107 paragraphs, DeepSeek V3.2, 4 batches)
- ZZYL ch3: DONE (82 paragraphs, DeepSeek V3.2, 12 batches @ 1500 chars/batch)
- Ceremonialis ch1: DONE (2 paragraphs, DeepSeek R1)
- Ceremonialis ch3: DONE (9 paragraphs, DeepSeek V3.2, 7 batches @ 3000→6000 chars)
- Language-aware batching solved the truncation issues (zh=1500, grc=6000)

**API comparison for translation:**
| Provider | Model | Context | Max Output | Cost (in/out per M) |
|----------|-------|---------|-----------|---------------------|
| DeepSeek | deepseek-chat (V3.2) | 128K | 8K | $0.28 / $0.42 |
| DeepSeek | deepseek-reasoner | 128K | 64K | $0.28 / $0.42 |
| Kimi | kimi-k2 (0905) | 256K | ~8K | $0.60 / $2.50 |
| Claude | Haiku 4.5 | 200K | 8K (64K ext) | $1.00 / $5.00 |
| Claude | Sonnet 4.5 | 1M | 8K (64K ext) | $3.00 / $15.00 |

**Decision:** Using deepseek-chat for cost. Batching handles 8K output limit.

**Language-specific density observation:**
- Classical Chinese (zh): VERY dense. 1 char ≈ 3-5 English words. 3000 source chars → 8K+ output tokens.
- Ancient Greek (grc): Moderate. 1 char ≈ 0.5-1 English words. 3000 source chars → ~2-3K output tokens.
- Latin (la): Similar to Greek.
- TODO: Make MAX_CHARS_PER_BATCH language-aware (e.g., zh=3000, grc=8000, la=8000)

### Database Setup (Session 2)

- Neon PostgreSQL (cloud, free tier)
- Schema pushed via `pnpm db:push` (drizzle-kit push)
- .env.local must be sourced before drizzle-kit commands: `set -a && source .env.local && set +a`
- Database seeded: 4 languages, 2 authors, 2 texts, 147 chapters (140 ZZYL + 7 Ceremonialis)
- Dev server works: pages load with correct data from DB
- Docker NOT available on this system — Neon is the path forward

### Code Changes (Session 2)

- Replaced `@anthropic-ai/sdk` with `openai` package (DeepSeek uses OpenAI-compatible API)
- `src/server/translation/client.ts` → OpenAI client with baseURL "https://api.deepseek.com"
- `scripts/translate-batch.ts` → uses `openai.chat.completions.create()`, model "deepseek-chat"
- Added paragraph chunking (MAX_CHARS_PER_BATCH = 8000)
- Added robust parsing: coerces string indices to numbers
- `.env.example` → DEEPSEEK_API_KEY replaces ANTHROPIC_API_KEY
- `.gitignore` → added API_keys_DO_NOT_COMMIT.txt

### Deployment Plan (Phase 8)

**GitHub remote:** https://github.com/translorentz/translation-wiki.git
**Current state:** 8 commits (7 ahead of origin), plus uncommitted DeepSeek migration

**Steps to go live:**
1. Commit DeepSeek migration changes
2. Push all commits to GitHub
3. User: Connect GitHub repo to Vercel (vercel.com → import project)
4. User: Set environment variables on Vercel:
   - DATABASE_URL = same Neon connection string
   - AUTH_SECRET = generate with `openssl rand -base64 32`
   - AUTH_URL = production URL (e.g., https://translation-wiki.vercel.app)
   - DEEPSEEK_API_KEY = same key (for any server-side translation features)
5. Deploy triggers automatically on push
6. Schema already applied to Neon (step already done)
7. Optional: Custom domain in Vercel dashboard

**Known issues to address:**
- Next.js 16 warns: "middleware" file convention deprecated, use "proxy" instead
  - This is non-blocking (still works), but should be migrated eventually
- NextAuth is beta (5.0.0-beta.30) — monitor for stable release
- CLAUDE.md still references @anthropic-ai/sdk — cosmetic, not blocking
- Only 5/147 chapters have translations (3 ZZYL + 2 Ceremonialis)
  - MVP is fine — shows the structure, more can be added later

**Production environment variables needed:**
| Variable | Source | Notes |
|----------|--------|-------|
| DATABASE_URL | Neon dashboard | Already configured in .env.local |
| AUTH_SECRET | `openssl rand -base64 32` | Must generate for production |
| AUTH_URL | Your Vercel domain | e.g., https://translation-wiki.vercel.app |
| DEEPSEEK_API_KEY | platform.deepseek.com | Same as dev |

### Commands Cheat Sheet

```bash
# Project setup
pnpm create next-app@latest translation-wiki --typescript --tailwind --eslint --app --src-dir
cd translation-wiki
pnpm add @trpc/server @trpc/client @trpc/tanstack-react-query @tanstack/react-query zod superjson drizzle-orm postgres next-auth@beta
pnpm add -D drizzle-kit @types/node vitest @vitejs/plugin-react jsdom @testing-library/react @testing-library/dom @testing-library/jest-dom vite-tsconfig-paths playwright @playwright/test
npx shadcn@latest init
npx shadcn@latest add button card input label table tabs dialog dropdown-menu

# Database
docker compose up -d  # starts local PostgreSQL
pnpm drizzle-kit generate  # generate migration from schema
pnpm drizzle-kit migrate  # apply migration
pnpm drizzle-kit studio  # GUI at localhost:4983

# Development
pnpm dev  # starts Next.js dev server with Turbopack
pnpm build  # production build
pnpm test  # vitest in watch mode
pnpm test run  # vitest single run
```

### Session 3: Local Verification (2026-01-23)

**Issue found:** Schema had `composition_year` and `composition_era` columns in code but not in the Neon database.
**Fix:** Ran `pnpm db:push` to sync schema. All pages now work.

**Verification results — all pages working:**
- Home (`/`): 200 — title "Deltoi", renders featured texts
- Browse texts (`/texts`): 200 — lists texts
- Text index (`/zh/zhu-xi/zhuziyulei`): 200 — chapter listing
- Chapter view (ZZYL ch1): 200 — Chinese content + translation rendered
- Chapter view (Ceremonialis ch1): 200 — Greek content rendered
- Edit page: 307 redirect to login (correct — protected)
- Login: 200
- Register: 200
- Search: 200
- Admin/users: 307 redirect to login (correct — protected)

**Uncommitted work still pending:**
- 66 ZZYL processed chapter files updated
- 7 Ceremonialis processed chapter files updated
- New text: chuanxilu (傳習錄) data + processing script
- Admin pages, home components, schema/auth/trpc changes
- `fix-chapter-titles.ts`, `process-chuanxilu.ts` scripts
- New `src/types/` directory

**Actions taken (continued):**
- Committed all pending changes: b50ba01 (104 files, +3748/-168 lines)
- Pushed to GitHub: b2d49af..b50ba01 main → main
- Vercel auto-deployed successfully (deployment status: success)
- Verified deltoi.com serves the new code (title "Deltoi", all pages 200)
- Created reference-guide.txt — structured quick reference for all sessions
- Updated CLAUDE.md: added session files section, fixed Anthropic→DeepSeek refs,
  added current deployment info, added Chuanxilu to initial texts list

**Discovered:** AUTH_URL env var on Vercel still set to translation-wiki.vercel.app
  (visible in Set-Cookie header). User needs to update this in Vercel dashboard.

**Next steps:**
- User: Update AUTH_URL on Vercel to https://deltoi.com
- Seed chuanxilu into the database
- Run more AI translations (most chapters still untranslated)
- Address middleware deprecation warning (non-blocking)

### Session 4: New Texts Processing & Full Translation (2026-01-23)

**New raw texts discovered in data/raw/:**
1. `deanima_cassiodorus/De_anima.txt` — Latin, 76KB, Cassiodorus "De Anima" (c. 540)
2. `elegia/elegia.txt` — Latin, 43KB, Henry of Settimello "Elegia" (c. 1190)
3. `lombards_of_b/langabardorum.txt` — Latin, 90KB, Erchempert "Historia Langobardorum Beneventanorum" (c. 889)
4. `regno/regno_sicile.txt` — Latin, 263KB, Hugo Falcandus "Liber de Regno Sicilie" (c. 1169)
5. `tongjian_jishi_benmo/` — Chinese, 6.4MB (45 files), Yuan Shu "通鑑紀事本末" (c. 1174)

**Processing completed:**
- Created scripts/process-new-texts.ts — processes all 4 non-trivial texts
- De Anima: 18 chapters (Roman numeral headers, paragraphs by blank lines)
- Elegia: 4 chapters/books (processed by earlier agent, verse grouped into paragraphs)
- Lombards: 82 sections (numbered, mostly single-paragraph sections)
- Regno: 56 chapters (1 prologue + 55 Roman numeral chapters, paragraphs by blank lines)
- Tongjian: 45 chapters (2 prefaces + 42 volumes + 1 afterword, deduplicated paragraphs)

**Database seeded:**
- 6 new authors: Wang Yangming, Cassiodorus, Henry of Settimello, Erchempert, Hugo Falcandus, Yuan Shu
- 6 new texts: Chuanxilu, De Anima, Elegia, Lombards, Regno, Tongjian
- 208 new chapters total (3 + 18 + 4 + 82 + 56 + 45)
- All pages return 200 on localhost:3000

**Translation progress (7 parallel background processes running):**
- De Anima (la, 18 ch): IN PROGRESS
- Elegia (la, 4 ch): IN PROGRESS
- Lombards (la, 82 ch): IN PROGRESS
- Regno (la, 56 ch): IN PROGRESS
- Tongjian (zh, 45 ch): IN PROGRESS — very large volumes, dense Chinese
- ZZYL (zh, 137 remaining): IN PROGRESS — 13+ batches per chapter
- Ceremonialis (grc, 5 remaining): IN PROGRESS — massive chapters (150K chars each)

**Translation API:** Using DeepSeek V3.2 (deepseek-chat), $0.28/$0.42 per M tokens
**All 7 processes running with 0 errors so far.**

**Known issue with Tongjian raw data:** Many paragraphs appear duplicated (each paragraph
repeated twice consecutively). Processing script deduplicates these automatically.

**Files created/modified this session:**
- scripts/process-new-texts.ts (NEW) — processes De Anima, Lombards, Regno, Tongjian
- data/processed/deanima/ (18 files)
- data/processed/lombards/ (82 files)
- data/processed/regno/ (56 files)
- data/processed/tongjian/ (45 files)
- data/processed/elegia/ (4 files, from earlier agent)

**User permissions granted (Session 4):**
- Always allowed to write/update logs, scratchpads, markdowns without asking
- Always allowed to run monitoring bash commands (sleep, tail, curl checks) without user input

**Next steps:**
- Wait for all 7 translation processes to complete
- Commit all new processed data + scripts
- Push to GitHub for Vercel auto-deploy
- Update reference-guide.txt with final translation counts

### Session 5: Poetry Display, HDNJ Processing, Parallel Translation (2026-01-23)

**Poetry display mode implemented:**
- Added `textType` field to texts table schema (varchar, "prose" | "poetry")
- Ptochoprodromos text set to textType="poetry" in seed-db.ts
- InterlinearViewer: accepts `textType` prop, passes `isPoetry` to ParagraphPair
- ParagraphPair: poetry mode uses:
  - Line numbers every 5th line (absolute positioned, tabular-nums)
  - Compact spacing (py-0.5 instead of py-3)
  - No row separators (border removed)
  - Left padding (pl-10 md:pl-12) for line number gutter
  - Header alignment padding matches content
- Chapter page passes `textData.textType` to InterlinearViewer
- Build verified, curl tested (correct CSS classes present)
- Committed as 241a6bf

**Ptochoprodromos translation:**
- Chapter 1 already had translation
- Chapter 2 translated successfully (poetry/verse text)
- First attempt killed by `| head -10` SIGPIPE — re-ran without pipe

**ZZYL translation parallelized:**
- Previous: 1 sequential worker (killed at ch 57/140)
- New: 4 parallel workers with --delay 4000:
  - Worker 1: ch 58-78
  - Worker 2: ch 79-99
  - Worker 3: ch 100-120
  - Worker 4: ch 121-140
- translate-batch.ts skips already-translated chapters (checks currentVersionId)

**Huang Di Nei Jing (黃帝內經) processing:**
- Found 55 raw files in data/raw/huang_di_nei_jing/ (Su Wen section only)
- File format: NNN_素問_Su_Wen_Title.txt
- Each file: title line, === separator, then alternating section headers + content
- Created scripts/process-huangdi.ts:
  - Strips === separators and section headers (lines ending with :)
  - Extracts content paragraphs with 1-based indexing
  - Output: data/processed/huangdineijing/chapter-NNN.json (55 files)
- Added to seed-db.ts:
  - Author: "Huangdi (Traditional Attribution)", slug "huangdi"
  - Text: "Huang Di Nei Jing (The Yellow Emperor's Classic of Medicine)", slug "huangdineijing"
  - Language: zh, compositionYear: -200

**HDNJ title scope fix:**
- User said HDNJ will be 81+81 chapters (Su Wen + Ling Shu) so title shouldn't be just Su Wen
- Updated seed-db.ts: title="Huang Di Nei Jing (The Yellow Emperor's Classic of Medicine)"
- Updated titleOriginalScript from "黃帝內經素問" to "黃帝內經"
- Updated description to mention both sections
- Fixed in database via temporary script _fix-hdnj-title.ts
- Note: inline `tsx -e` failed due to esbuild not supporting `!` non-null assertion

**HDNJ translation started (3 parallel workers):**
- Worker 1: ch 1-18
- Worker 2: ch 19-37
- Worker 3: ch 38-55
- All with --delay 4000

**Discussion pages plan created:**
- Plan file: ~/.claude/plans/radiant-spinning-scone.md
- New tables: discussion_threads, discussion_posts
- tRPC router: discussions.ts (listByChapter, getThread, createThread, createPost, toggleResolved, togglePinned)
- Pages: /[chapter]/discussion/ and /[chapter]/discussion/[threadId]
- Components: ThreadList, ThreadView, CreateThreadForm, PostReplyForm
- All logged-in users can create/reply; admins can pin

**Background translation status (end of session):**
- be044fa: Tongjian (in progress, batch 35/42 on current chapter)
- b6a3898: ZZYL 58-78 (in progress, batch 19/20)
- b0ab038: ZZYL 79-99 (in progress, batch 10/15)
- bd76b8e: ZZYL 100-120 (completed ch 101-102)
- b7ea0d0: ZZYL 121-140 (completed ch 123)
- bd051ef: HDNJ 1-18 (completed ch 9-13)
- bb4c2cb: HDNJ 19-37 (completed ch 26-30)
- b503646: HDNJ 38-55 (completed ch 47-51)

**Errors this session:**
- `| head -10` kills translation script with SIGPIPE — never pipe long-running scripts
- `tsx -e` inline code can't use `!` non-null assertion — use temp script file instead
- Created SCRATCH.md when convention is scratch-notes.txt — deleted via git rm

**Files created this session:**
- scripts/process-huangdi.ts (NEW)
- data/processed/huangdineijing/ (55 chapter files)

**Files modified this session:**
- src/components/interlinear/InterlinearViewer.tsx (textType/isPoetry prop)
- src/components/interlinear/ParagraphPair.tsx (poetry display mode)
- src/app/(wiki)/[lang]/[author]/[text]/[chapter]/page.tsx (passes textType)
- scripts/seed-db.ts (added HDNJ author/text, textType for ptochoprodromos)
- src/server/db/schema.ts (added textType column to texts table)

**Carmina Graeca Medii Aevi — FULLY COMPLETE (raw files + processed JSON done):**
- Raw .txt files: 21 files in data/raw/carmina-graeca/, total 10,957 lines
- Quality: Grade A (Critic Agent evaluation after all fixes)
- See docs/carmina-graeca-scratchpad.md for full agent notes
- See docs/carmina-graeca-critiques.md for per-chapter quality evaluations

**Carmina Graeca Medii Aevi — Implementation Details:**
- File: data/difficult_extra_processing/carmina_graeca_medii_aevi_multiple_titles.txt
- 1.4MB, 23,770 lines of OCR from W. Wagner's 1874 edition
- Contains 21 distinct medieval Greek poems/narratives in one file
- Pipeline: scripts/lib/carmina/ (6 modules + orchestrator)
  - title-finder.ts: 21 hardcoded title positions + heuristic ALL-CAPS detector
  - text-splitter.ts: splits file into 21 sections by title boundaries
  - content-classifier.ts: classifies lines as verse/apparatus/noise/intro/empty
  - verse-extractor.ts: extracts clean verse, strips numbers, groups into 15-line paragraphs
  - quality-checker.ts: validates output with thresholds
  - output-formatter.ts: writes standard chapter JSON
- Key insight: medieval Greek verse NEVER contains Arabic numerals
  - Any embedded digit (not at line start) = apparatus
  - This is the most powerful discriminator since Latin editorial text is OCR'd into Greek Unicode
- Classifier patterns for apparatus detection:
  - hasEmbeddedNumbers(): strips leading editorial number, checks for remaining digits
  - MULTIPLE_NUMBERS: 3+ numbers on one line (standalone, no sigla needed)
  - EDITORIAL_BRACKETS: [ ] { } never appear in verse
  - CODEX_ABBREV: οοα/οοά (= Latin "cod." rendered as Greek)
  - LATIN_IN_GREEK: known Latin-in-Greek-script patterns (Βατγβίαπ = "Bursian", etc.)
  - VERSE_REF: ν. + digit pattern
  - Extended sigla set: Α, Β, Μ, Ρ, Δ, Κ, Υ, Ν, Τ
- Results: PASS=13, WARN=8, FAIL=0, 10,952 verse lines, 1,270 paragraphs
- Contamination rate: 0.055% (6 lines, all OCR artifacts not real apparatus)
- CONTENT_END_LINE fixed from 21200 to 22885 (Belisarius poem extends to line 22882)
- Chapter 21 ending verified: final verse "οὐδὲ θεάσονταί ποτε ὅσα κ᾿ ἂν τραγῳδοῦσιν" present
- Output: data/processed/carmina-graeca/chapter-001.json through chapter-021.json
- seed-db.ts updated: added Wagner as author, Carmina Graeca as text (poetry type)
- Pipeline COMPLETE — ready for database seeding when DATABASE_URL is available
- Background translation workers still running (ZZYL 66+, 117+)
- Tongjian translation: chapters 1-15 done, chapters 16-45 being translated by 2 new workers
  - Old workers killed (had JSON parse errors, single-retry only)
  - translate-batch.ts improved: translateBatchWithRetry() — 3 retries + batch splitting + placeholder fallback
  - Worker 1 (b28bb83): chapters 16-30
  - Worker 2 (b10363e): chapters 31-45

**Discussion pages verification:**
- Schema, router, components, client wrappers, pages all exist and build cleanly
- Confirmed in `pnpm build` output: routes listed correctly
- Schema tables already synced to Neon (db:push returned "No changes detected")

**HDNJ translation complete:**
- All 3 workers finished with 0 errors
- 55 chapters (Su Wen) fully translated

### Session 6: Translation Gap-Filling & Sangam Corpus Organisation (2026-01-23)

**Context:** All prior translation workers from session 5 have stopped (no processes running
at session start). Many chapters already translated, but gaps remain in ZZYL and Tongjian.

**Translation workers launched (gap-filling, auto-skips translated chapters):**

ZZYL (4 workers, --delay 5000):
- Worker b69b215: ch 1-35
- Worker bce854e: ch 36-70
- Worker b2393ec: ch 71-105
- Worker b3e2c72: ch 106-140

Tongjian (3 workers, --delay 5000):
- Worker b3d7c9a: ch 1-15 → COMPLETE IMMEDIATELY (all 15 already translated)
- Worker b76003b: ch 16-30
- Worker b83ad01: ch 31-45

**Initial observations from worker output:**
- ZZYL: workers skipping many chapters (ch 1-3, 52-56, 73-77, 107-111 confirmed translated)
  meaning significant translation progress from prior sessions
- Tongjian ch 1-15: fully translated from prior sessions
- Tongjian ch 16-30, 31-45: some gaps remain (workers actively translating)

**Sangam Tamil Corpus Organiser launched (agent a2e8431):**
- Task: Survey 1000+ Tamil corpus files, find Ettuthokai & Pattuppāṭṭu texts,
  clean headers/footers, output pure verse to data/raw/sangam/
- Agent has its own docs: docs/sangam-scratchpad.md, docs/sangam-reference.md
- Agent scripts go in: scripts/sangam/
- Output goes in: data/raw/sangam/ettuthokai/ and data/raw/sangam/pattuppattu/
- This corpus is NOT for translation — it is for organisation and cleaning only

**Tamil corpus overview (data/difficult_extra_processing/tamil_corpus/):**
- 1,768,068 total lines across 1000+ .txt files
- Source: Project Madurai (Tamil Virtual Academy) e-texts
- Mix of Sangam-era classics, medieval devotional works, modern literature
- Files named with numeric prefix + Tamil title
- Typical format: Project Madurai header → verse text → footer/colophon
- Goal: Extract Sangam-era works (Ettuthokai + Pattuppāṭṭu) as clean text

**Ettuthokai (Eight Anthologies) — works to find:**
1. நற்றிணை (Narrinai) — 400 poems
2. குறுந்தொகை (Kuruntokai) — 401 poems
3. ஐங்குறுநூறு (Ainkurunuru) — 500 poems
4. பதிற்றுப்பத்து (Patirruppattu) — 100 poems
5. பரிபாடல் (Paripadal) — 70 poems (22 survive)
6. கலித்தொகை (Kalittokai) — 150 poems
7. அகநானூறு (Akananuru) — 400 poems
8. புறநானூறு (Puranānuru) — 400 poems

**Pattuppāṭṭu (Ten Long Poems) — works to find:**
1. திருமுருகாற்றுப்படை (Tirumurukarruppadai)
2. பொருநராற்றுப்படை (Porunararruppadai)
3. சிறுபாணாற்றுப்படை (Cirupanarruppadai)
4. பெரும்பாணாற்றுப்படை (Perumpanarruppadai)
5. முல்லைப்பாட்டு (Mullaippattu)
6. மதுரைக்காஞ்சி (Maturaikkanci)
7. நெடுநல்வாடை (Netunalvatai)
8. குறிஞ்சிப்பாட்டு (Kurincippattu)
9. பட்டினப்பாலை (Pattinappalai)
10. மலைபடுகடாம் (Malaipatakatam)

**Translation gap analysis:**
- Wrote scripts/_check-translation-gaps.ts — finds chapters with empty paragraphs
- Wrote scripts/_check-empty-source.ts — distinguishes empty-source from genuine gaps
- Result: 117 genuine gaps across 55 chapters (source non-empty, translation empty)
- Worst cases: ZZYL ch126 (12 gaps), tongjian ch3 (10 gaps), ZZYL ch139 (8 gaps),
  ZZYL ch47 (8 gaps), ZZYL ch68 (5 gaps)
- Root cause: API failures during batch translation left empty strings
  (not the placeholder text, just empty)
- The translate-batch.ts skip logic means these chapters won't be retried by workers
  (they already have currentVersionId set)

**Gap-filler script created and launched:**
- Script: scripts/fill-translation-gaps.ts
- Approach: Scan all translations, find empty paragraphs with non-empty source,
  retranslate just those paragraphs, create a new TranslationVersion with gaps filled
- Worker b5f5064: running with --delay 3000
- No conflict with main translation workers (operates on different chapter sets)

**Background processes — FINAL STATUS:**

| Worker | Task | Status | Result |
|--------|------|--------|--------|
| b69b215 | ZZYL ch 1-35 | DONE | 2 translated, 33 skipped |
| bce854e | ZZYL ch 36-70 | DONE | 1 translated, 34 skipped |
| b2393ec | ZZYL ch 71-105 | DONE | 1 translated, 34 skipped |
| b3e2c72 | ZZYL ch 106-140 | DONE | 1 translated, 34 skipped |
| b76003b | Tongjian ch 16-30 | RUNNING | 6 done (ch 19-24), skipped 16-18, on ch 25 |
| b83ad01 | Tongjian ch 31-45 | RUNNING | 6 done (ch 33-38), skipped 31-32, on ch 39 |
| b5f5064 | Gap-filler | DONE | 55/55 chapters fixed, 0 failures |
| a2e8431 | Sangam organiser | DONE | 3 texts extracted (Akananuru, Purananuru, Porunararruppadai) |

**ZZYL Translation: 140/140 COMPLETE**
- All 140 chapters now have translations (135 from prior sessions, 5 newly translated)
- Gap-filler fixed 55 chapters with empty paragraphs — 117 paragraphs filled, 0 failures

**Tongjian Translation progress:**
- Previously done: ch 1-18 (15 from prior + 16-18 from another run)
- Newly translated this session: ch 19-24, 33-38 (12 chapters)
- In progress: ch 25-30, 39-45 (12 more chapters)
- Total when complete: ch 1-45 (all 45 chapters)

**Gap-filler final results:**
- 55 chapters across multiple texts (ZZYL, Tongjian, Carmina Graeca)
- 117 genuine gaps all filled successfully
- Each fixed chapter got a new TranslationVersion (version 2)
- Notable fills: ZZYL ch126 (12 gaps), ZZYL ch139 (8 gaps), Tongjian ch3 (10 gaps)

**Sangam agent progress — Akananuru sanity check:**

Source file: `229_அகநானுறு - மூலம்.txt` (9,111 lines)
Script: `scripts/sangam/clean-akananuru.ts` (276 lines, well-documented)

The agent wrote a sophisticated tokenizer-based parser that:
- Classifies each line as 'num', 'text', or 'section'
- Identifies the 3 Akananuru sections: களிற்றியாணை நிரை (1-120),
  மணிமிடை பவளம் (121-300), நித்திலக்கோவை (301-400)
- Distinguishes poem numbers from in-poem line markers (multiples of 5)
  using predecessor context (poem numbers preceded by total_count or section header)
- Extracts verse lines and writes individual poem files

Results: 395/400 poems extracted + invocation.txt = 396 files
Missing: poems 104, 131, 319, 396, 400

Root cause of missing poems: corrupted line-counts in source file
- "1 5" instead of "15" (line 2463, before poem 104)
- 3 total instances of number-with-space in the source
- The tokenizer classifies "1 5" as text, not num → predecessor check fails

Quality issues found in poem-399.txt:
1. Poems 399 and 400 merged into one file (boundary not detected at end of text)
2. Leaked editorial matter:
   - `.399-18` apparatus marker embedded in verse line 18
   - `அகநானுறு  முற்றிற்று` (colophon: "Akananuru completed")
   - `This page was last updated on 3 September 2005.` (Project Madurai footer)
3. Scattered `.` markers (edition line references) in some lines

Poems verified correct (spot-checked):
- Poem 001 (19 lines): correct — Palai Patiya Perunkadunko's separation poem
- Poem 050 (14 lines): correct length for Akananuru
- Poem 100 (18 lines): correct — neythal landscape poem mentioning Purantai port
- Poem 300 (22 lines): correct — nittilakovai section, clean verse

Line length distribution: 14-22 lines per poem (expected range 13-31 for Akananuru)

Pattuppattu progress:
- All 10 directories created in data/raw/sangam/pattuppattu/
- Porunararruppadai: poem.txt written
- Other 9: directories exist (agent still working on them)

Other scripts created:
- scripts/sangam/clean-puranānuru.ts (Puranānuru processing)
- scripts/sangam/clean-porunar.ts (Porunararruppadai processing)

Agent docs NOT yet written (docs/sangam-scratchpad.md, docs/sangam-reference.md)
— agent prioritised extraction work over documentation

**Fixes needed (for agent or future session):**
1. Handle corrupted numbers: treat "N N" (digit-space-digit) as a single number
2. Fix poem 399/400 boundary (last poem merge)
3. Strip colophon line "அகநானுறு  முற்றிற்று"
4. Strip Project Madurai footer "This page was last updated..."
5. Remove apparatus markers (`.NNN-NN` patterns, stray `.` between lines)
6. Verify Puranānuru and other Ettuthokai texts similarly
7. Write docs/sangam-scratchpad.md and docs/sangam-reference.md

### Tamil Literature Search — Results (Session 6)

Searched the Project Madurai corpus for 4 specific texts requested by user:

| Text | Status | Output |
|------|--------|--------|
| Perunkathai (Konguvelir) | ABSENT | Only prose retelling + related Udayanakumara Kaviyam found |
| Culamani (Tolamoli Thevar) | PARTIAL | Carukkams 1-7, 10-12 present; 8-9 missing |
| Nandikkalambakam | COMPLETE | 88 poems + supplements, 760 lines |
| Yashodhara Kaviyam | PARTIAL | Carukkams 3-5 only; 1-2 missing |

Processed files placed in:
- data/raw/udayanakumara-kaviyam/ (2,660 lines, 6 kandams, 367 verses)
- data/raw/culamani/ (2 part files, 7,172 lines total)
- data/raw/nandikkalambakam/ (760 lines, all 88 poems)
- data/raw/yashodhara-kaviyam/ (1,495 lines, carukkams 3-5 with commentary)

Notes:
- Perunkathai is genuinely rare (massive 10,000+ line epic, not widely digitized)
- Culamani and Nandikkalambakam are pure verse; Yashodhara has interspersed commentary
- Missing portions would need sourcing from other digital libraries

### Tamil Translation Module — IMPLEMENTED (Session 6 continued)

Implemented the Gemini-based Tamil translation pipeline as planned:

**Files created/modified:**
1. `src/server/translation/gemini-client.ts` — GoogleGenAI client wrapper (singleton)
2. `src/server/translation/prompts.ts` — Added Tamil 'ta' language instructions
   - Covers Sangam landscape symbolism (tinai), akam/puram themes, archaic vocabulary
3. `scripts/translate-tamil.ts` — Batch translation script using Gemini 2.5 Flash
4. `.env.example` — Added GEMINI_API_KEY placeholder

**Dependency added:** `@google/genai` v1.38.0

**Key parameters:**
- Model: gemini-2.5-flash
- Temperature: 0.3 (low for faithful translation)
- MAX_CHARS_PER_BATCH: 4000 (Tamil verse is moderate density)
- Max output tokens: 8192 per API call
- Retry logic: 3 attempts + batch splitting (same as DeepSeek pipeline)
- Skip logic: checks `currentVersionId` (same as DeepSeek pipeline)
- Filters to language code 'ta' only

**End-to-end test results:**
- Tested with Akananuru poem 300 (first 4 lines, neytal imagery)
- Gemini correctly translated classical Tamil, preserving fishing/seashore imagery
- JSON output format correct: `[{"index": 0, "text": "..."}]`
- Response wrapped in markdown code fence (handled by stripping logic)

**Usage:**
```bash
pnpm tsx scripts/translate-tamil.ts --text <tamil-slug> [--start N] [--end N] [--delay MS]
```

**Prerequisites before running:**
1. Tamil language ('ta') must be added to languages table
2. Tamil author(s) and text(s) must be seeded into DB
3. Chapters must be seeded with sourceContent

### Tamil Supplement Files Processing (Session 7)

**Task**: Process two supplement files to complete previously-gapped Tamil texts.

**Files found**:
- `data/difficult_extra_processing/tamil_corpus/supplement_culamani_89.txt` (6,247 lines)
- `data/difficult_extra_processing/tamil_corpus/supplement_yashodhara-kaviyam.txt` (6,690 lines)

**Yashodhara Kaviyam supplement (carukkams 1-2, verses 1-160)**: GOOD QUALITY
- Contains: kaappu (invocation, v1-4), first carukkam (v5-73), second carukkam (v74-160)
- Format: verse + commentary (urai), matching existing carukkams 3-5 file format
- Encoding: mostly intact Tamil Unicode with minor character drops
- Verse continuity: ALL 160 verses present, ZERO gaps
- Boundary: verse 160 -> 161 connects perfectly to existing file
- Processing: stripped Project Madurai header (lines 1-666), stripped 146 embedded page numbers
- Output: `data/raw/yashodhara-kaviyam/yashodhara-kaviyam-carukkam-1-2.txt` (5,879 lines)
- Status: TEXT NOW COMPLETE (verses 1-330, all 5 carukkams)

**Culamani supplement (carukkams 8-9, verses 827-1554)**: SEVERELY CORRUPTED
- Contains: carukkam 8 (v827-1130), carukkam 9 (v1131-1554)
- Encoding: HEAVILY CORRUPTED — PDF-to-text extraction with non-Unicode Tamil font
  - Only ~30-40% of Tamil characters render correctly
  - Latin characters and symbols mixed into Tamil text
  - Verse text largely unreadable for translation purposes
- Verse numbers: intact and detectable (630/728 found via pattern matching)
- Boundary: verse 1554 -> 1555 connects correctly to existing part-3 file
- Processing: stripped Project Madurai header (lines 1-71), stripped embedded page numbers
- Output: `data/raw/culamani/part-2-carukkam-08-09.txt` (6,036 lines)
- Status: FILE SAVED BUT CORRUPTED — needs replacement from better source
- Note: The text is unusable for translation without a clean re-digitization

**Completeness assessment**:
- Yashodhara Kaviyam: NOW COMPLETE (verses 1-330 across 2 files, all 5 carukkams)
- Culamani: STRUCTURALLY complete (827-1554 fills the gap) but TEXT CORRUPTED
- Culamani needs re-sourcing from a better digitization for carukkams 8-9

### Nandikkalambakam Cleaning (Session 7)

- Script: `scripts/sangam/clean-nandikkalambakam.ts`
- Input: `data/raw/nandikkalambakam/nandikkalambakam.txt` (760 lines)
- Output: `data/raw/nandikkalambakam/nandikkalambakam-clean.txt` (868 lines, 641 verse lines)
- Poems: 114 total (kappu + 88 main + 22 supplement-many-MSS + 3 supplement-few-MSS)
- Removed: 113 meter labels, 2 headers, 2 editorial notes, 2 supplement headers
- Preserved: kalippa structural markers (taravu, taazhisai, aragam, ambotharangam, thanicchol, suritagam)
- Note: No poem 35 in source (duplicate poem 34 exists — traditional numbering quirk)

### Tamil DB Seeding + First Translation (Session 7)

**Website Language Updater agent (a125fab)**: Adding Tamil ('ta') to DB
- Adds language entry: code='ta', name='Tamil', displayName='Classical Tamil'
- Adds author: Mudathirumaran (முடத்திருமாறன்), Sangam period
- Adds text: Porunararruppadai (பொருநராற்றுப்படை), slug='porunararruppadai', textType='poetry'
- Processes raw text (248 lines) → JSON paragraphs → seeds into DB

**Tamil Translator agent (aed743c)**: First Gemini Tamil translation
- Waits for seeding to complete (polls DB up to 10 times)
- Sanity-checks source text quality in DB
- Tests Gemini translation with small excerpt
- Runs full translation: `scripts/translate-tamil.ts --text porunararruppadai`
- This is our FIRST Tamil translation — quality validation important

**Expected website URL**: https://deltoi.com/ta/mudathirumaran/porunararruppadai/chapter-1

**Next steps for Tamil (after first translation verified):**
1. Process and seed Akananuru (400 poems → 400 chapters)
2. Process and seed Nandikkalambakam (114 poems)
3. Process and seed Yashodhara Kaviyam (5 carukkams)
4. Process and seed Udayanakumara Kaviyam (6 kandams)
5. Source clean Culamani carukkams 8-9 from alternative digitization
6. Source remaining 15 Sangam works from Project Madurai

### Tamil Translation Notes + Review Pipeline (Session 7 cont.)

**Tamil note-writer agent (ad1496f)**: COMPLETED
- Wrote 2 comprehensive scholarly documents:
  1. `docs/tamil-translation-notes/porunararruppadai-translator-notes.md` (647 lines, 39.7KB)
     - All 17 paragraphs analyzed with Tamil quotations and quality ratings
     - Archaic vocabulary tables (musical instruments, weapons, flora/fauna, court terms)
     - Tinai imagery analysis + tinai-exchange passage explanation
     - Proper names catalog, literary devices, verse structure analysis
     - Genre analysis (arruppadai convention), quality self-assessment
     - 10 specific difficult passages with confidence levels
  2. `docs/tamil-translation-notes/gemini-tamil-observations.md` (421 lines, 23.2KB)
     - Classical vs modern Tamil vocabulary handling (80-85% correct)
     - JSON format compliance: perfect, no repair needed
     - Temperature 0.3 analysis: too conservative for poetry, recommends 0.4-0.5
     - Batch size analysis: 4000-char batches adequate, recommends 6000-8000 for Tamil
     - 6 specific prompt improvements suggested (genre, vocabulary, similes, cultural context)
     - Model comparison: Gemini > DeepSeek for Tamil; Gemini Pro recommended for canonical texts
     - Vocabulary hits/misses: 19 correct vs 16 misses (errors cluster in food, music, material culture)
     - Key error: "narantham" (citron) mistranslated as "civet" — DEFINITE ERROR

**Tamil reviewer agent (acc837f)**: RUNNING
- Has read all source materials (Tamil ur-text, English translation, translator notes)
- Writing independent review with fresh perspective

### New Text Processing Agents (Session 7 cont.)

**Guliang Zhuan agent (ae85d94)**: RUNNING
- Processed 12 chapters from raw data
- Seeded into DB (author: Guliang Chi, text: Commentary of Guliang)
- Translation: ch 1-4 DONE, currently translating ch 5 (batch 2/7 of 12 total chapters)
- Uses DeepSeek deepseek-chat model with 3000ms delay

**Baihu Tong agent (a2d8baa)**: RUNNING
- Processed and seeded (author: Ban Gu, text: Baihu Tong)
- Translation worker launched (background bash bb78898)
- Processing 43 topics of Confucian classical scholarship

**Yi Zhou Shu agent (a2e691b)**: RUNNING
- Added author: Zhou Court Scribes (周室史官) to seed-db.ts
- Added text: Yi Zhou Shu (逸周書), 61 extant chapters
- Seeding into DB (Zhou Court Scribes author added successfully)
- Source: ancient Zhou dynasty documents not in canonical Shang Shu

**Yi Li agent (a72a764)**: RUNNING
- Added author: Zheng Xuan (鄭玄, ed.) to seed-db.ts
- Added text: Yi Li (儀禮), 17 chapters
- Seeding into DB (Zheng Xuan author + Yi Li text added, chapters loading)
- Commentary separation: Zheng Xuan's annotations marked with [注] prefix
- One of the Three Ritual Classics (三禮) of Confucianism

### Tongjian Translation Workers (Session 7 cont.)

**Worker b83ad01 (ch 31-45)**: RUNNING
- Chapters 33-40: DONE (368+274+342+372+311+287+445+426 paragraphs)
- Currently: Chapter 41, batch 5/35
- 1 retry occurred (ch 35, batch 27/45) — recovered successfully
- Progress: 10/15 chapters complete

**Worker b76003b (ch 16-30)**: RUNNING
- Chapters 19-25: DONE (344+351+388+361+321+327+409 paragraphs)
- Currently: Chapter 26, batch 27/41
- Progress: 10/15 chapters complete

### Porunararruppadai Master Retranslation (Session 8 — 2026-01-23)

**Task:** Retranslate Porunararruppadai (248-line Sangam Tamil poem) using improved prompt
**Agent:** Claude Opus 4.5 (Master Reviewer/Translator)
**Translation engine:** Gemini 2.5 Flash

**What was done:**
1. Read all 4 scholarly notes files (translator notes, observations, reviewer assessment, retranslation requests)
2. Expanded Tamil prompt in prompts.ts from 8 lines to 45 lines (6 improvement categories)
3. Added --retranslate flag to translate-tamil.ts (creates new version instead of skipping)
4. Reduced MAX_CHARS_PER_BATCH from 4000 to 2500 (prevents output truncation with detailed prompt)
5. Increased maxOutputTokens from 8192 to 16384
6. First attempt (4000 chars): 5 empty paragraphs due to output truncation — defective v2 deleted
7. Second attempt (2000 chars, 4 batches): all 17 paragraphs translated successfully
8. Cleaned up: deleted defective intermediate, renumbered to clean v1 -> v2 chain

**Results (8 retranslation requests):**
- 5/8 FULLY FIXED: narantham=citron, celva=vocative, vaNTal=sand-houses, uRaZntum=alternating, food passage specificity
- 2/8 IMPROVED: evening/morning metaphor (now comprehensible), seven-step sequence (clearer order)
- 1/8 PARTIAL: garland "not bound by thread" (still not ideal — should be "on invisible thread")

**Grade improvement:** B- -> B/B+
**Report:** docs/tamil-translation-notes/master-retranslation-report.md

**Key technical insight:** Tamil poetry with a detailed prompt produces much more output per source character than prose. The 4000-char batch size that works for Chinese prose is too large for Sangam poetry + expanded prompt. 2500 chars is the sweet spot.

### Baihu Tong (白虎通義) Processing and Translation (Session 10 — 2026-01-24)

**Task:** Process, seed, and translate the Baihu Tong (Comprehensive Discussions in the White Tiger Hall), a Han dynasty Confucian text by Ban Gu (79 CE).

**Source:** 10 raw files in data/raw/baihu_tong/ (01_卷一.txt through 10_卷十.txt)
- Structure: topics delimited by ====================\nTitle\n====================
- 43 topics across 10 juan, 453 paragraphs, 57,776 characters total
- Traditional Chinese, clean quality, minimal lacunae (□ characters)

**Steps completed:**
1. Examined all 10 raw files — Traditional Chinese, no OCR issues, section-delimited format
2. Wrote scripts/process-baihu-tong.ts — maps 43 topics to bilingual titles
3. Ran processing: 43 chapters output to data/processed/baihu-tong/chapter-NNN.json
4. Added Ban Gu author and Baihu Tong text entry to scripts/seed-db.ts
5. Seeded to database: 43 chapters, 453 paragraphs
6. Translated all 43 chapters: 0 errors, all complete
7. Verified: 43/43 chapters translated, sample translation quality verified

**Author entry:**
- Name: "Ban Gu", nameOriginalScript: "班固", slug: "ban-gu"
- Era: "Eastern Han dynasty (32–92 CE)"

**Text entry:**
- Title: "Baihu Tong (Comprehensive Discussions in the White Tiger Hall)"
- slug: "baihu-tong", languageCode: "zh", compositionYear: 79
- compositionEra: "建初四年, Eastern Han dynasty"
- processedDir: "data/processed/baihu-tong"

### Non-Sangam Tamil Full Workflow (Session 9 — 2026-01-24)

**Task:** Process and translate 3 complete non-Sangam Tamil texts through the full 4-stage workflow, one at a time.

**Texts (in order):**
1. Nandikkalambakam (நந்திக்கலம்பகம்) — 114 poems, 868 lines, c. 850 CE, Pallava period
2. Yashodhara Kaviyam — 5 carukkams, 330 verses (Jain epic)
3. Udayanakumara Kaviyam — 6 kandams, 367 verses

**Text 1: Nandikkalambakam**
- Stage 1 agent: a472c67 (processing + seeding + translating via Gemini) — ~59/114 done
- Stage 2 agent: a28b7f4 (reviewer) — reviewed 64/114 poems, B- grade, waiting for rest
- Stage 3 agent: PENDING (master retranslator — launch after Stage 1+2 both COMPLETE)
- Raw: data/raw/nandikkalambakam/nandikkalambakam-clean.txt (868 lines)
- Structure: kappu + 88 main poems + 22 supplement (many-MSS) + 3 supplement (few-MSS) = 114 chapters
- Author: "Various Poets" (பல்கவிஞர்கள்), slug: nandikkalambakam-poets
- Text slug: nandikkalambakam, textType: poetry, language: ta
- Reviewer findings: 19 GOOD, 31 ADEQUATE, 14 PROBLEMATIC; key issue = Sangam prompt on medieval text

**Porunararruppadai Editorial Clarification (Session 9)**
- Agent a123b07 completed editorial clarification pass
- Title updated: "Porunararruppadai" → "The War-Bard's Guide (Porunararruppadai)"
- TranslationVersion v3 created (editorial clarification of v2)
- All Tamil terms translated into English with [transliteration] on first use only
- This approach is now MANDATORY in Agent 3 (Master Retranslator) workflow

**Pipeline Design Update (Session 9)**
- Updated docs/tamil-translation-orchestration.md with 3-agent staggered pipeline
- Agent 2 (Reviewer) starts when ≥ 20 poems are translated (staggered with Agent 1)
- Agent 3 (Master) waits for BOTH Stage 1+2 COMPLETE (systemic prompt improvement)
- Agent 3 now includes MANDATORY editorial clarification pass (English terms + [transliteration])
- Shared coordination file: docs/tamil-translation-notes/<text-slug>-pipeline-progress.md

### Fengsu Tongyi (風俗通義) Processing and Translation (Session 10 — 2026-01-24)

**Task:** Process, seed, and translate the Fengsu Tongyi (Comprehensive Meaning of Customs) by Ying Shao (c. 195 CE).

**Source:** 11 raw files in data/raw/Fengsu_Tongyi_Chapters/
- Mixed structure: some files have `====================` separators + blank lines, others have each line as a paragraph
- Traditional Chinese, clean quality
- Total: 311 paragraphs across 11 chapters

**Steps completed:**
1. Examined all 11 raw files — identified two formats (separator-delimited vs line-per-paragraph)
2. Wrote scripts/process-fengsu-tongyi.ts — each non-blank, non-separator line = one paragraph
3. Ran processing: 11 chapters output to data/processed/fengsutongyi/chapter-NNN.json
4. Added Ying Shao author and Fengsu Tongyi text entry to scripts/seed-db.ts
5. Seeded to database: 11 chapters, 311 paragraphs
6. Translated all 11 chapters: 0 errors, all complete

**Chapter paragraph counts:** 5, 21, 34, 19, 17, 24, 48, 16, 47, 40, 40

**Author entry:**
- Name: "Ying Shao", nameOriginalScript: "應劭", slug: "ying-shao"
- Era: "Eastern Han dynasty (c. 140-204 CE)"

**Text entry:**
- Title: "Fengsu Tongyi (Comprehensive Meaning of Customs)"
- slug: "fengsutongyi", languageCode: "zh", compositionYear: 195
- compositionEra: "Eastern Han dynasty (c. 195 CE)"
- processedDir: "data/processed/fengsutongyi"

**Bug fixed during development:**
- Initial processing script accumulated consecutive lines into single paragraphs
  (worked for separator-delimited files but broke line-per-paragraph files)
- Fix: treat every non-blank, non-separator line as its own paragraph
- Before fix: chapters 1, 4, 5, 6, 8 showed 1 paragraph each
- After fix: correct counts (5, 19, 17, 24, 16 respectively)

**Website URL:** https://deltoi.com/zh/ying-shao/fengsutongyi/

### Nandikkalambakam Independent Review — Stage 2 (2026-01-24)

**Task:** Review 64 translated Nandikkalambakam poems as independent reviewer (Stage 2 of Tamil pipeline)
**Agent role:** Reviewer Agent (Stage 2)
**Poems reviewed:** 64 (chapters 1-64, i.e., kappu + poems 1-63)

**Method:**
1. Read all 64 translations from Neon DB (mcp__Neon__run_sql)
2. Read Tamil source texts from data/processed/nandikkalambakam/ for comparison
3. Read existing prompts.ts to understand what guidance was given to Gemini
4. Read previous Porunararruppadai review for format reference
5. Compared each poem's translation against Tamil source for accuracy

**Key findings:**
- Overall grade: B- (solid first draft with systemic issues)
- 19/64 GOOD, 31/64 ADEQUATE, 14/64 PROBLEMATIC
- Critical issue: Sangam-era prompt applied to medieval (850 CE) text — genre mismatch
- Kalambakam structural labels (taravu, taazhisai, etc.) entirely stripped from translation
- Battle name "Vellaaru/Thellaaru" spelled 5 different ways across poems
- "Thondai" polysemy (region/fruit/garland) unresolved — causes confusion in ~5 poems
- Ironic death-euphemism "ascend to heaven" sometimes reads as reward not punishment
- "Kali" misidentified as goddess (should be Kali Yuga/turbulence in medieval context)
- "Kanchukan" wrongly treated as proper name (is epithet of Nandi himself)
- Poem 50 (ch 51) — untranslatable wordplay (sandalippu) rendered as gibberish

**Outputs created:**
1. docs/tamil-translation-notes/nandikkalambakam-pipeline-progress.md — Status tracker
2. docs/tamil-translation-notes/nandikkalambakam-reviewer-notes.md — Full review (B- grade, per-poem table, vocabulary errors, systemic issues, genre observations)
3. docs/tamil-translation-notes/nandikkalambakam-retranslation-requests.md — Prioritized fix list (5 HIGH, 12 MEDIUM, 8 LOW)

**Recommendations for Stage 4 (Master Retranslator):**
1. Create Nandikkalambakam-specific prompt supplement (medieval Tamil, Pallava history, kalambakam conventions)
2. Standardize all proper names before retranslation
3. Fix the 14 PROBLEMATIC poems
4. Wait for remaining 50 poems to be translated with improved prompt before retranslating first 64

### Yi Zhou Shu (逸周書) Re-processing with Commentary Brackets (Session 10 — 2026-01-24)

**Task:** Re-process Yi Zhou Shu to preserve [bracketed commentary] annotations from Kong Chao.

**Problem:** The previous processing stripped all brackets. The raw files use [square brackets]
for inline commentary, which must be preserved for the frontend to render in dark maroon.

**Source:** 62 files in data/raw/yi_zhou_shu/
- 8 files contain [brackets]; 5 have meaningful commentary in main text
- Total preserved commentary brackets: 117 out of 121

**Steps completed:**
1. Rewrote scripts/process-yi-zhou-shu.ts (removed bracket stripping, kept duplicate detection)
2. Ran processing: 62 chapters, 81 paragraphs, 40,021 chars
3. Deleted existing Yi Zhou Shu data from DB (62 chapters, 78 translations)
4. Re-seeded database: 62 chapters with brackets preserved
5. Translated all 62 chapters: 0 errors
6. Verified bracket preservation in translations

**Database state:** Text ID 19, slug yi-zhou-shu, 62/62 chapters translated
**Website URL:** https://deltoi.com/zh/zhou-scribes/yi-zhou-shu/

### Yi Li (儀禮) Processing & Translation (2026-01-24)

**Task:** Process and translate the Yi Li (Ceremonies and Rites), one of the Three Ritual Classics.

**Raw files examined:** 17 .txt files in data/yi_li/ (not data/raw/yi_li/)
- Named: 01_士冠禮.txt through 17_有司.txt
- Each file = 1 traditional chapter of the Yi Li
- Format: plain text, one paragraph per line, no headers or separators

**CRITICAL FINDING — Commentary Status:**
The raw files contain ONLY the base text (經/jing). NO Zheng Xuan commentary is present.
Searched for all known commentary markers (注, 鄭注, 注曰, brackets, etc.) — none found.
All occurrences of 注/傳/疏 characters in the files are regular vocabulary words, not markers.
The source is a "jing only" edition without the traditional Zheng Xuan annotations.

**Processing approach:**
- Created scripts/lib/yili/types.ts — type definitions + chapter title reference table
- Created scripts/lib/yili/parser.ts — parser with commentary detection (for future use)
- Created scripts/process-yi-li.ts — main processing script
- Output: data/processed/yi-li/chapter-001.json through chapter-017.json
- All paragraphs typed as "text" (no commentary present to mark with [注])

**Processing results (17/17 chapters):**
| Chapter | Chinese | English | Paragraphs |
|---------|---------|---------|-----------|
| 1 | 士冠禮 | Capping Ceremony for a Gentleman | 29 |
| 2 | 士昬禮 | Marriage Ceremony for a Gentleman | 30 |
| 3 | 士相見禮 | Ceremony of Introduction for a Gentleman | 12 |
| 4 | 鄉飲酒禮 | District Drinking Ceremony | 26 |
| 5 | 鄉射禮 | District Archery Ceremony | 51 |
| 6 | 燕禮 | Banquet Ceremony | 30 |
| 7 | 大射 | Grand Archery | 46 |
| 8 | 聘禮 | Ceremony of Embassy | 34 |
| 9 | 公食大夫禮 | Duke's Feast for a Grand Officer | 18 |
| 10 | 覲禮 | Ceremony of Audience | 13 |
| 11 | 喪服 | Mourning Garments | 13 |
| 12 | 士喪禮 | Funeral Ceremony for a Gentleman | 38 |
| 13 | 既夕禮 | Eve-of-Burial Ceremony | 18 |
| 14 | 士虞禮 | Sacrifice of Repose for a Gentleman | 12 |
| 15 | 特牲饋食禮 | Single-Victim Offering Ceremony | 21 |
| 16 | 少牢饋食禮 | Lesser Animal Offering Ceremony | 22 |
| 17 | 有司 | The Assisting Officers | 40 |
| TOTAL | | | 453 |

**Seed-db.ts additions:**
- Author: "Zheng Xuan (ed.)" / slug "zheng-xuan" / era "Eastern Han dynasty (127-200 CE)"
- Text: "Yi Li (Ceremonies and Rites)" / slug "yi-li" / language "zh" / compositionYear -200

**Database seeding:** Successful — 17 chapters inserted

**Translation:** COMPLETE — 17/17 chapters translated with DeepSeek V3.2
- First worker (ch 1-8): completed before SIGPIPE killed it (head -50 issue)
- Second worker (ch 9-17): completed all remaining chapters, 0 errors
- Total paragraphs translated: 453

**Website URL:** https://deltoi.com/zh/zheng-xuan/yi-li/

### Session 11: Naming Consistency & Pipeline Progress (2026-01-24)

**Naming Convention Change — "English Name (Transliteration)" for ALL languages:**

Updated 14 text titles in both the Neon database (via SQL transaction) and scripts/seed-db.ts:

| Old Format | New Format |
|------------|-----------|
| Zhu Zi Yu Lei (Classified Conversations...) | Classified Conversations of Master Zhu (Zhu Zi Yu Lei) |
| Chuan Xi Lu (Instructions for Practical Living) | Instructions for Practical Living (Chuan Xi Lu) |
| Tongjian Jishi Benmo (Narratives from...) | Narratives from the Comprehensive Mirror (Tongjian Jishi Benmo) |
| Huang Di Nei Jing (The Yellow Emperor's...) | The Yellow Emperor's Classic of Medicine (Huang Di Nei Jing) |
| Guliang Zhuan (Commentary of Guliang) | Commentary of Guliang (Guliang Zhuan) |
| Baihu Tong (Comprehensive Discussions...) | Comprehensive Discussions in the White Tiger Hall (Baihu Tong) |
| Yi Li (Ceremonies and Rites) | Ceremonies and Rites (Yi Li) |
| Yi Zhou Shu (Lost Book of Zhou) | Lost Book of Zhou (Yi Zhou Shu) |
| Fengsu Tongyi (Comprehensive Meaning...) | Comprehensive Meaning of Customs (Fengsu Tongyi) |
| Gaoshi Zhuan (Biographies of Lofty...) | Biographies of Lofty Scholars (Gaoshi Zhuan) |
| Ptochoprodromika (Poems of Poor Prodromos) | Poems of Poor Prodromos (Ptochoprodromika) |
| Carmina Graeca Medii Aevi (Medieval Greek Poems) | Medieval Greek Poems (Carmina Graeca Medii Aevi) |
| Nandikkalambakam | The Anthology of Nandi (Nandikkalambakam) |
| Porunararruppadai | The War-Bard's Guide (Porunararruppadai) |

Texts already in English-first format (no change needed): On the Ceremonies of the Byzantine Court,
On the Soul, Elegy on Misfortune, History of the Lombards of Benevento, The Book of the Kingdom of Sicily.

**Rule for future texts:** Always use "English Descriptive Name (Original Transliteration)" format.
Latin/Greek texts that are already commonly known by English titles (e.g., "On the Soul") don't need
the parenthetical unless the original title is well-known (e.g., "On the Soul (De Anima)" is optional).

**Nandikkalambakam Pipeline Status:**
- Stage 1 (agent a472c67): 109/114 poems translated, still running
- Stage 2 (agent a28b7f4): COMPLETED — reviewed 64 poems, B- grade
  - Key issue: Sangam-era prompt applied to medieval (850 CE) text
  - Outputs: nandikkalambakam-reviewer-notes.md, nandikkalambakam-retranslation-requests.md
- Stage 3: PENDING — will launch immediately after Stage 1 completes
  - Must include editorial clarification pass (English terms + [transliteration])
  - Must address medieval-vs-Sangam prompt mismatch

**Other agents completed this session:**
- Guliang Zhuan (ae85d94): 12/12 chapters, all translated, COMPLETE
- Yi Li (a72a764): 17/17 chapters, 453 paragraphs, COMPLETE
- Baihu Tong (a2d8baa): 43/43 chapters, COMPLETE
- Fengsu Tongyi (a6a5e09): 11/11 chapters, COMPLETE
- Gaoshi Zhuan (a451a68): 4/4 chapters, COMPLETE
- Yi Zhou Shu (a127b87): 62/62 chapters with commentary brackets, COMPLETE

**Background workers still running:**
- Tongjian: b76003b, b83ad01 (translating remaining chapters 25-45)

**Actions taken (continued):**
- Committed and pushed naming changes: de59658 → Vercel deploying
- Nandikkalambakam Stage 1 confirmed COMPLETE (114/114 via DB query)
- Launched Nandikkalambakam Stage 3 agent (aa88334): Master Retranslator
  - Reads reviewer notes, improves Tamil prompt for medieval text, retranslates all 114, editorial clarification
- Launched Yashodhara Kaviyam Stage 1 agent (a1cae1c) IN PARALLEL:
  - Processing raw text from data/raw/yashodhara-kaviyam/
  - Seeding into DB, translating with Gemini 2.5 Flash
  - Will create pipeline progress file when done

**Currently running (4 agents + 2 Tongjian workers):**
- aa88334: Nandikkalambakam Stage 3 (Master Retranslator)
- a1cae1c: Yashodhara Kaviyam Stage 1 (processing + translating)
- a9ce61b: Udayanakumara Kaviyam Stage 1 (processing + translating)
- b76003b, b83ad01: Tongjian translation workers

**Udayanakumara Kaviyam Stage 1 COMPLETE (agent a9ce61b, 2026-01-24):**
- Processed raw text (2,660 lines) into 6 chapters (366 verses, 1 short of stated 367)
- Created processing script: scripts/process-udayanakumara-kaviyam.ts
- Added author "Anonymous Jain Poet (Udayana cycle)" + text entry to seed-db.ts
- Seeded into DB (text ID 22, 6 chapters)
- Translated all 6 chapters via Gemini 2.5 Flash
- Cleaned up duplicate translations from parallel runs
- Pipeline progress: docs/tamil-translation-notes/udayanakumara-kaviyam-pipeline-progress.md
- STAGE 1 COMPLETE

**Odyssey Commentary Cleaning Agent launched (ad294a1, 2026-01-24):**
- Source: TWO volumes — `commentariiadhom01eust_djvu.txt` + `commentariiadhom02eust_djvu.txt`
- Text: Eustathius of Thessalonica, Commentary on Homer's Odyssey (both volumes)
- Vol 1: ~25,879 lines (Odyssey books 1-12 approx.)
- Vol 2: exists in same folder, covers Odyssey books 13-24 approx.
- Agent initially instructed for Vol 1 only; will be resumed for Vol 2 after completion
- Coordination file: `docs/eustathius-odyssey-agent-instructions.md` (both volumes documented)
- Agent writes own docs: `docs/plan-eustathius-processing.md`, `docs/eustathius-scratchpad.md`
- Architecture: Following Carmina Graeca pipeline pattern (`scripts/lib/eustathius/` modules)
- Output: `data/raw/eustathius-odyssey/` + `data/processed/eustathius-odyssey/chapter-NNN.json`
- Language: grc, Author: Eustathius of Thessalonica (12th c. CE)

**Yashodhara Kaviyam Stage 1 COMPLETE (agent a1cae1c, 2026-01-24):**
- Processed raw text (2 files) into 5 chapters (330 verses across 5 carukkams)
- Created processing script: scripts/process-yashodhara-kaviyam.ts
- Added author "Anonymous Jain Poet" + text entry to seed-db.ts
- Seeded into DB (5 chapters), translated all 5 via Gemini 2.5 Flash
- Pipeline progress: docs/tamil-translation-notes/yashodhara-kaviyam-pipeline-progress.md
- STAGE 1 COMPLETE

**Stage 2 Reviewers launched (2026-01-24):**
- afa7e45: Yashodhara Kaviyam Stage 2 Reviewer (reading translations, writing notes)
- ae734cc: Udayanakumara Kaviyam Stage 2 Reviewer (reading translations, writing notes)
- Both will write reviewer-notes.md + retranslation-requests.md in docs/tamil-translation-notes/

**Greek XML TEI Parser Agent launched (a95b70a, 2026-01-24):**
- Source: 3 TEI-XML files in `data/greek_xml/` (First1KGreek/Perseus corpus)
  1. Epistula ad Diognetum (Pseudo-Justin Martyr, 2nd c. CE) — 50KB
  2. Historia Nova (Zosimus, 5th-6th c. CE) — 1.2MB
  3. In Aristotelis Sophisticos Elenchos Paraphrasis (Anonymous) — 489KB
- Task: Build a flexible, reusable TEI-XML parser for Greek texts
- Architecture: `scripts/lib/greek-xml/` (types, tei-parser, text-extractor, chapter-splitter, validator)
- Main script: `scripts/process-greek-xml.ts`
- Output: `data/raw/<slug>/` + `data/processed/<slug>/chapter-NNN.json`
- Agent writes own docs: `docs/plan-greek-xml-processing.md`, `docs/greek-xml-scratchpad.md`
- Self-testing: Agent iterates until all 3 texts produce clean, consistent output

**Eustathius Dual-Agent Quality Pipeline launched (2026-01-24):**
- Greek Reviewer Agent (a8e9017) launched alongside Processing Agent (ad294a1)
- Shared collaboration doc: `docs/eustathius-collaboration.md` (both read/write)
- Reviewer's own scratchpad: `docs/eustathius-reviewer-scratchpad.md`
- Workflow: Processor produces → Reviewer critiques → Processor fixes → iterate until Grade A
- Same pattern as Carmina Graeca dual-agent pipeline (which achieved Grade A)

**Currently running (7 agents + 2 Tongjian workers):**
- aa88334: Nandikkalambakam Stage 3 (Master Retranslator)
- afa7e45: Yashodhara Kaviyam Stage 2 (Reviewer)
- ae734cc: Udayanakumara Kaviyam Stage 2 (Reviewer)
- ad294a1: Odyssey Commentary Processing Agent (OCR pipeline, Vol 1)
- a8e9017: Odyssey Commentary Reviewer Agent (quality evaluator)
- a95b70a: Greek XML TEI Parser Agent (building reusable parser for 3 texts)
- b76003b: Tongjian translation worker (ch 19+)
- b83ad01: Tongjian translation worker (ch 33+)

**Yashodhara Kaviyam Stage 2 COMPLETE (agent afa7e45, 2026-01-24):**
- Overall grade: C+ (significant processing bug)
- CRITICAL: `process-yashodhara-kaviyam.ts` fails to strip commentary from 2nd source file
  - Chapters 3-5 contaminated with commentary prose (30-46% of paragraphs)
- Missing translations in Ch 1: verses 57-73 (token exhaustion)
- 194/330 verses (59%) need retranslation
- Stage 3 must: fix processing script → re-seed ch 3-5 → retranslate all

**Greek XML Output Reviewer Agent launched (a329f69, 2026-01-24):**
- Reviews output of Greek XML Parser Agent (a95b70a)
- Shared doc: `docs/greek-xml-collaboration.md`
- Reviewer scratchpad: `docs/greek-xml-reviewer-scratchpad.md`
- Same dual-agent pattern as Eustathius pipeline

**Greek XML TEI Parser COMPLETE (agent a95b70a, 2026-01-24):**
- All 3 texts processed: 334 chapters, 1,276 paragraphs, 606K chars
- Epistula ad Diognetum: 12 chapters, 100 paragraphs (all PASS)
- Historia Nova (Zosimus): 287 chapters, 1,071 paragraphs (all PASS)
- Sophistici Elenchi Paraphrasis: 35 chapters, 105 paragraphs (all PASS)
- Pipeline: scripts/lib/greek-xml/ (6 modules) + scripts/process-greek-xml.ts
- Dependency added: fast-xml-parser v5.3.3
- Documentation: docs/plan-greek-xml-processing.md, docs/greek-xml-scratchpad.md
- Next: Greek XML Reviewer Agent (a329f69) evaluating output quality

**Currently running (7 agents + 2 Tongjian workers):**
- aa88334: Nandikkalambakam Stage 3 (Master Retranslator)
- ae734cc: Udayanakumara Kaviyam Stage 2 (Reviewer)
- ad294a1: Odyssey Commentary Processing Agent
- a8e9017: Odyssey Commentary Reviewer Agent
- a329f69: Greek XML Output Reviewer Agent (reviewing 334 processed chapters)
- b76003b: Tongjian translation worker (ch 19+)
- b83ad01: Tongjian translation worker (ch 33+)

**Next steps:**
1. When Nandikkalambakam Stage 3 completes: verify quality improvement
2. When Udayanakumara Stage 2 completes: launch Stage 3 for both Tamil texts
   - Yashodhara: fix processing script FIRST, re-seed, retranslate
3. When Greek XML Reviewer (a329f69) confirms quality: launch 3 PARALLEL translation agents
   - Agent 1: Epistula ad Diognetum (12 chapters) — seed + translate
   - Agent 2: Historia Nova / Zosimus (287 chapters) — seed + translate (large!)
   - Agent 3: Sophistici Elenchi Paraphrasis (35 chapters) — seed + translate
   - All use DeepSeek (grc language, existing translate-batch.ts)
   - Each agent handles actual text vs commentary distinction
4. When Odyssey dual agents reach Grade A: resume Processor for Vol 2
5. After both Odyssey volumes processed: seed into DB + translate (grc)
6. Commit all new processed data + scripts when agents complete

---

## Session 2026-01-24: Greek XML TEI Parser — COMPLETE

### Task
Built a modular TEI-XML parser pipeline for First1KGreek corpus files.

### Files Created
- `scripts/lib/greek-xml/types.ts` — TypeScript interfaces + TEXT_CONFIGS
- `scripts/lib/greek-xml/tei-parser.ts` — Core XML parsing (fast-xml-parser)
- `scripts/lib/greek-xml/text-extractor.ts` — Text cleaning/normalization
- `scripts/lib/greek-xml/chapter-splitter.ts` — Division tree -> flat chapters
- `scripts/lib/greek-xml/validator.ts` — Quality checking
- `scripts/lib/greek-xml/index.ts` — Module exports
- `scripts/process-greek-xml.ts` — CLI processing script
- `docs/greek-xml-parsing-notes.md` — Structural analysis
- `docs/plan-greek-xml-processing.md` — Architecture + how-to guide
- `docs/greek-xml-scratchpad.md` — Working notes

### Results
| Text | Slug | Chapters | Paragraphs | Characters | Status |
|------|------|----------|------------|------------|--------|
| Epistula ad Diognetum | diognetum | 12 | 100 | 16,823 | 12 PASS |
| Historia Nova (Zosimus) | historia-nova | 287 | 1,071 | 416,216 | 287 PASS |
| In Soph. Elenchos Paraphrasis | sophistici-elenchi-paraphrasis | 35 | 105 | 173,137 | 35 PASS |
| **TOTAL** | | **334** | **1,276** | **606,176** | **0 WARN/FAIL** |

### Dependencies Added
- `fast-xml-parser` v5.3.3

### Remaining Steps
1. Add author + text entries to `scripts/seed-db.ts`
2. Run `pnpm tsx scripts/seed-db.ts` to seed into database
3. Launch translation workers on each text

---

## Session 2026-01-24 — Eustathius Odyssey Commentary Processing Pipeline

### Task
Process `data/difficult_extra_processing/commentariiadhom01eust_djvu.txt` (25,880 lines OCR) into
clean structured chapter files. Source: Volume 1 of Eustathius of Thessalonica's Commentary on
Homer's Odyssey (Leipzig 1825 Weigel edition, Internet Archive scan).

### Architecture
6-module TypeScript pipeline in `scripts/lib/eustathius/`:
- `types.ts` — type definitions (RhapsodyEntry, TextSection, ClassifiedLine, etc.)
- `book-splitter.ts` — hardcoded ΡΑΨΩΔΙΑ boundaries for 12 sections (ch0=preface, ch1-11=Odyssey books)
- `content-classifier.ts` — 14-rule priority classifier (commentary|page_header|margin_number|page_number|empty|noise)
- `commentary-extractor.ts` — line joining, margin stripping, paragraph splitting at verse refs
- `quality-checker.ts` — validates Greek%, paragraph count, noise leakage
- `output-formatter.ts` — writes JSON to data/processed/ and TXT to data/raw/

Main orchestrator: `scripts/process-eustathius.ts`

### Key Technical Decisions
1. **Hardcoded boundaries** vs dynamic detection: ΡΑΨΩΔΙΑ headers are too garbled for reliable auto-detection.
   Manually identified 12 book boundaries by analyzing all 50+ ΡΑΨΩΔΙΑ headers in the file.
2. **ΡΑΨΩΔΙΑ regex**: Required 3 iterations. Final pattern: `/[»Ῥ]*Ρ{0,2}ΑΨ[ΙΩΏΣΨ1-9\s.,]*[ΩΏΙΊ1ΣΤ][ΔΙ41][ΑΙ4.,\s\d]*/`
   Key challenge: OCR replaces Greek with numerals (Δ→4, Ι→1) and adds spaces/dots.
3. **Paragraph splitting**: Uses "(Vers. N.)" references as natural break points, falls back to
   sentence boundaries (period + space), then character count (MAX_PARAGRAPH_CHARS=800).
4. **Margin stripping**: Removes Bekker numbers (10,20,30,40,50,60), edition page numbers (3-4 digits),
   and garbled margin annotations. Applied per-line before joining.
5. **Short paragraph filter**: Paragraphs <20 chars after cleaning are filtered as noise leakage.
6. **Leading page number fix**: Pattern updated to handle `1466(Vers...` (no space after digits).

### Results (Final Run — All Issues Fixed)
- **12 chapters**: 0=Preface/Prooemium, 1-11=Odyssey Books A-Λ
- **Status**: ALL 12 PASS (previously 7 PASS, 5 WARN)
- **Total stats**: 20,583 commentary lines, 3,450 paragraphs, 1,955,254 total characters
- **Greek char %**: 93.9%-96.3% for commentary chapters (59.6% for Latin/Greek preface)
- **Average paragraph length**: 553-587 chars across chapters

### Chapter Details
| Ch | Book | Lines | Paragraphs | Chars | Greek% | Status |
|----|------|-------|------------|-------|--------|--------|
| 0 | Preface | 181 | 23 | 12,727 | 59.6% | PASS |
| 1 | Α (Alpha) | 4,740 | 607 | 336,234 | 96.1% | PASS |
| 2 | Β (Beta) | 3,096 | 406 | 227,932 | 96.1% | PASS |
| 3 | Γ (Gamma) | 781 | 106 | 61,031 | 96.0% | PASS |
| 4 | Δ (Delta) | 3,031 | 387 | 225,847 | 95.5% | PASS |
| 5 | Ε (Epsilon) | 2,592 | 355 | 199,161 | 95.6% | PASS |
| 6 | Ζ (Zeta) | 1,608 | 225 | 127,933 | 96.0% | PASS |
| 7 | Η (Eta) | 850 | 107 | 60,952 | 93.9% | PASS |
| 8 | Θ (Theta) | 1,962 | 271 | 153,554 | 95.9% | PASS |
| 9 | Ι (Iota) | 3,634 | 508 | 288,047 | 95.7% | PASS |
| 10 | Κ (Kappa) | 1,879 | 265 | 149,742 | 95.7% | PASS |
| 11 | Λ (Lambda) | 1,377 | 190 | 112,094 | 96.3% | PASS |

### Issues Investigated and Fixed
1. **Book 3 short section (781 lines)**: Confirmed legitimate — the Γ→Δ boundary is correct.
   Odyssey Book 3 commentary is genuinely shorter in this edition.
2. **Short paragraph leakage** (Ch1: 3 noise fragments like "αὗται quia dn"): Fixed by filtering
   paragraphs <20 chars in extractor.
3. **Page number leakage** (Ch2: "...πατὴρ 0 ὡς 1 706", Ch8: "...μνῶν. 1603"):
   - Fixed leading page number pattern: `^\d{3,4}[᾿'΄]?\s*(?=[\s(])` handles `1466(` case
   - Added trailing Bekker strip at end of line
   - Added trailing multi-digit garble strip: `/(\s+\d{1,2}){2,}\s*$/`

### Output Locations
- Processed JSON: `data/processed/eustathius-odyssey/chapter-000.json` through `chapter-011.json`
- Raw TXT: `data/raw/eustathius-odyssey/chapter-00-preface-prooemium.txt` through `chapter-11-odyssey-book-11.txt`
- Quality report: `data/processed/eustathius-odyssey/quality-report.json`
- Documentation: `docs/plan-eustathius-processing.md`

## 2026-01-24: Session 18 — UI Fixes, Data Cleanup, Translation Progress

### Completed This Session
1. **Search language filter** (agent a259297): Added toggleable Badge filters to search page, URL-persisted (?lang=grc,la)
2. **Homepage button**: Changed "Register to Contribute" → "Search Texts" (links to /search)
3. **Zhouyi-zhengyi cleanup**: Deleted 4 scraping artifact chapters (TOC/copyright) from DB + disk
4. **Erya-zhushu cleanup**: Deleted chapter 1 (Siku TOC + ctext.org nav artifacts), stripped copyright from ch2
5. **Chapter title parsing** (agent a1da75c): Extracted parseChapterTitle() to src/lib/utils.ts, applied across all pages (sidebar, headers, search results, edit/history/discussion). Handles nested parens.
6. **Language filter fix**: Search only shows languages with actual texts (removes English/Tamil from filter)
7. **Tamil prompts**: Added Tamil (ta) language instructions to prompts.ts

### Translation Progress Snapshot (128 background workers active)
| Text | Workers | Done/Total | % |
|------|---------|-----------|---|
| eustathius-odyssey | 16 | 31/37 | 84% |
| lunyu-zhushu | 12 | 21/27 | 78% |
| zhouyi-zhengyi | 8 | 52/100 | 52% |
| gongyang-zhushu | 8 | 11/30 | 37% |
| mengzi-zhushu | 8 | 6/18 | 33% |
| guliang-zhushu | 4 | 7/21 | 33% |
| zuozhuan-zhengyi | 12 | 13/43 | 30% |
| erya-zhushu | 4 | 3/10 | 30% |
| shangshu-zhengyi | 8 | 7/24 | 29% |
| liji-zhengyi | 12 | 12/59 | 20% |
| zhouli-zhushu | 12 | 8/44 | 18% |
| yili-zhushu | 4 | 6/51 | 12% |
| liji-zhushu | 8 | 1/29 | 3% |

### Diarium Urbis Romae — 6-Agent Quality Pipeline (CONCURRENT MODEL)
Source: Stefano Infessura's Diary of the City of Rome (1890 Tommasini ed.)
Language: Italian (15th-century Romanesco) + Latin passages, ~23K lines per OCR scan
All 5 agents running concurrently, communicating via shared markdown docs:
  - Primary Text Agent A (a967fa5) — processing scan 1 → clean_copy_a/
  - Primary Text Agent B (a93ee58) — processing scan 2 → clean_copy_b/
  - Reviewer A (abe38cf) — critiques Agent A, writes to joint-a.md
  - Reviewer B (a69ff47) — critiques Agent B, writes to joint-b.md
  - Bridge Reviewer (a2ffcb5) — cross-references both teams, writes bridge-annotations.md
Master Reviewer & Translator: PENDING (launches after all 5 sign off)
Documentation: docs/diarium/orchestration.md (master tracking)
Output: data/difficult_extra_processing/diarium_urbis_romae/clean_copy_{a,b}/ → data/raw/diarium-urbis-romae/

### Data Issues Found (Chapter Titles Audit)
Many Shisan Jing texts have Chinese-only chapter titles with no English. Need a script to add English translations:
- Priority: kongzi-jiayu (44ch), liji-zhushu (29ch), lunyu-zhushu (21ch), mengzi-zhushu (15ch)
- Simple volume labels: liji-zhengyi, zhouyi-zhengyi, zhouli-zhushu, yili-zhushu, zuozhuan-zhengyi
- Format goal: "中文標題 (English Translation)" — same as carmina-graeca, tongjian, zhuziyulei

---

## 2026-01-24: Session 19 (Continuation)

### Status Check
- All 5 Diarium agents still running (a967fa5, a93ee58, abe38cf, a69ff47, a2ffcb5)
- Translation workers still active: shangshu-zhengyi, zuozhuan-zhengyi, mengzi-zhushu, liji-zhushu, zhouli-zhushu, liji-zhengyi

### Translation Progress Update
| Text | Translated/Total | Status |
|------|-----------------|--------|
| carmina-graeca | 21/21 | COMPLETE |
| tongjian | 45/45 | COMPLETE |
| zuozhuan-zhengyi | 42/43 | Nearly done |
| mengzi-zhushu | 29/29 | COMPLETE |
| shangshu-zhengyi | 28/34 | In progress |
| liji-zhengyi | 47/71 | In progress |
| zhouli-zhushu | 40/55 | In progress |
| liji-zhushu | 8/33 | In progress |

Note: Several texts have more chapters in DB than total_chapters field (duplicate chapters from Shisan Jing seeding). Workers are making progress regardless.

### Diarium Pipeline — FINAL STATUS (updated late session)

**All 5 reviewers/agents COMPLETE, Master Reviewer RUNNING:**

| Agent | Final Grade | Lines | Notes |
|-------|-------------|-------|-------|
| Agent A | B+ | 7,360 | 5 iterations, 12-pass TypeScript pipeline |
| Reviewer A | SIGNED OFF | — | Conditional approval at B+ |
| Agent B | B- | 9,493 | 4 iterations, 365 broken-line defect discovered |
| Reviewer B | COMPLETE | — | Graded B- after iteration 3, didn't see line-break issue |
| Bridge Reviewer | SIGNED OFF | — | Pass 2 complete, recommends Agent A as base |
| Master Reviewer | RUNNING | — | Reconciling both outputs |

**Key finding**: Bridge Reviewer discovered Agent B has 365 lines starting with punctuation (mid-sentence breaks never rejoined). This makes Agent A the clear winner for base text despite having more inline markers.

**Italian language preparation COMPLETE:**
- Italian language `it` inserted into database
- Translation prompt added for 15th-century Romanesco dialect
- Stefano Infessura author entry in seed-db.ts
- Diarium Urbis Romae text entry in seed-db.ts

### Translation Progress Update (final)
| Text | Translated/Total | Status |
|------|-----------------|--------|
| liji-zhengyi | 57/56 | ✓ COMPLETE |
| zhouli-zhushu | 49/42 | ✓ COMPLETE |
| shangshu-zhengyi | 33/22 | ✓ COMPLETE |
| carmina-graeca | 21/21 | ✓ COMPLETE |
| tongjian | 45/45 | ✓ COMPLETE |
| zuozhuan-zhengyi | 43/43 | ✓ COMPLETE |
| mengzi-zhushu | 29/29 | ✓ COMPLETE |
| yili-zhushu | 23/51 | 🔄 45% (workers running) |
| liji-zhushu | 11/29 | 🔄 38% (workers running) |

### Diarium Master Reviewer Code Location
- Reconciliation programs: `scripts/lib/diarium-master/`
- Final output: `data/raw/diarium-urbis-romae/`
- Master scratchpad: `docs/diarium/master-scratchpad.md`
- Master documentation: `docs/diarium/master-documentation.md`
- Communication channels (joint-a/b.md) not yet utilized
- All agents still running — expected to iterate based on reviewer feedback

## 2026-01-25: Session 20 (Continuation from Session 19)

### Diarium Urbis Romae — PIPELINE COMPLETE

**Master Reviewer (a2ab05f): COMPLETE**

Final reconciliation successful:
- Output: `data/raw/diarium-urbis-romae/diary-full.txt` (7,252 lines)
- Artifacts removed: 0 carets, 0 pipes, 0 headers, 0 apparatus vocabulary
- Year markers preserved: 53 (for navigation)
- Scripts created: `scripts/lib/diarium-master/` (4 TypeScript modules)

**Processing & Seeding COMPLETE:**
- Processing script: `scripts/process-diarium.ts` 
- Output: `data/processed/diarium-urbis-romae/` (64 chapters)
- Seeded to database: 64 chapters (January 25, 2026)

**Translation Workers Started:**
- Worker 1: chapters 1-10
- Worker 2: chapters 11-32
- Worker 3: chapters 33-64

**Translation Quality Review Agent (addddd2): RUNNING**
- Will sample translated paragraphs and compare to source
- Will grade translation quality (A/B/C/D/F)
- Will recommend if Gemini-based Italian/Latin module is needed

### Translation Prompt Updates
- Italian translation prompt updated to emphasize BILINGUAL nature (Romanesco + Latin)
- Text description in seed-db.ts updated to note Latin/Romanesco mixture

### Background Translation Workers Still Running
- yili-zhushu: ~45% complete
- liji-zhushu: ~38% complete
- diarium-urbis-romae: just started (0-3% depending on worker)

---

## 2026-01-24: Session 19 — Diarium Complete + Mobile Toggle + Rizhilu

### Diarium Urbis Romae — TRANSLATION COMPLETE
- All 66 chapters translated with 0 errors
- 3 workers completed: bceafc8 (ch1-22), ba0b219 (ch23-44), b699139 (ch45-66)
- Paragraph segmentation fix (v2) applied before translation
- Section headers like "III. HISTORIE DOPO IL RITORNO..." properly stripped

### Mobile Toggle Feature — IMPLEMENTED
Agent a517451 added mobile-only toggle to hide original source text:

**Files Created:**
- `src/hooks/useIsMobile.ts` — Mobile viewport detection hook (768px breakpoint)
- `src/hooks/useLocalStorage.ts` — Persisted state hook (SSR-safe)
- `src/hooks/index.ts` — Barrel export
- `src/components/interlinear/MobileSourceToggle.tsx` — Floating action button

**Files Modified:**
- `src/components/interlinear/InterlinearViewer.tsx` — Toggle state integration
- `src/components/interlinear/ParagraphPair.tsx` — Conditional source hiding

**Design:**
- Fixed bottom-right FAB (floating action button)
- Eye/EyeOff icons from lucide-react
- Text labels: "Hide Original" / "Show Original"
- State persisted in localStorage (key: `hideSourceText`)
- Only visible on mobile (<768px viewport)

### Rizhilu (日知錄) — IN PROGRESS
Agent a400ec2 completed full pipeline:
- 32 chapters (one per volume)
- 498,926 characters
- 4 translation workers running (logs at /tmp/rizhilu-worker{1,2,3,4}.log)
- Author: Gu Yanwu (顧炎武, 1613-1682)
- Text slug: `rizhilu`

### Active Translation Workers
| Text | Workers | Status |
|------|---------|--------|
| Diarium Urbis Romae | 3 | ✅ COMPLETE (66/66) |
| Rizhilu | 4 | 🔄 In Progress |
| Shisan Jing Zhushu | ~128 | 🔄 In Progress |
| Eustathius Odyssey | ~16 | 🔄 In Progress |

---

---

## 2026-01-24: Armenian Language Initiative (Session 19 continued)

### Overview
Three new Armenian texts discovered in `data/raw/`:
1. **kaitser** (76 files) - "Կայdelays" (The Sparks) by Raffi - autobiographical novel
2. **anna_saroyan** (1 file) - Epistolary novel by Perch Proshyan
3. **arshagouhi_teotig** (1 file) - Travel memoir about 1909 Adana massacre

### Agents Launched

| Agent ID | Task | Status |
|----------|------|--------|
| aecc115 | Create Armenian Gemini translator module | ✅ COMPLETE |
| a744647 | Prepare website for Armenian language | ✅ COMPLETE |
| a1eba8e | Translate sample kaitser chapter to txt | ✅ COMPLETE |

### Files Created/Modified

**New Files:**
- `scripts/translate-armenian.ts` - Armenian translation script (Gemini-based)
- `data/armenian-sample-review/kaitser-ch1-original.txt` - Sample original (25,966 bytes)
- `data/armenian-sample-review/kaitser-ch1-translation.txt` - Sample translation (15,495 bytes)
- `data/armenian-sample-review/translation-info.md` - Translation metadata

**Modified Files:**
- `scripts/seed-db.ts` - Added Armenian language
- `src/server/translation/prompts.ts` - Added Armenian translation prompt
- `src/components/interlinear/ParagraphPair.tsx` - Added Armenian font mapping

### Key Finding: Gemini Content Filtering
- **Issue**: Gemini 2.5 Flash BLOCKED the kaitser translation with "PROHIBITED_CONTENT"
- **Reason**: Historical themes (tax collector torture, poverty, threats of slavery)
- **Solution**: DeepSeek V3 successfully translated the content
- **Recommendation**: Use DeepSeek for Armenian texts with difficult historical content

### Database State
- Armenian language added: code `hy`, display name `Հdelays`
- Language ID: 7
- Website ready to display Armenian texts

### Next Steps
1. ~~Spin up translation review agent~~ IN PROGRESS
2. Write Armenian translation observations doc
3. Decide: Use DeepSeek or Gemini for Armenian based on review
4. Process kaitser, anna_saroyan, arshagouhi_teotig texts

---

## 2026-01-25: Session 22 — CLAUDE.md Reorganization + Genre Categorization

### CLAUDE.md Reorganization — COMPLETE

Condensed CLAUDE.md from 1071 lines to 243 lines (77% reduction) with supplementary files:

| File | Lines | Purpose |
|------|-------|---------|
| `CLAUDE.md` | 243 | Condensed operational guide |
| `ARCHIVED_CLAUDE.md` | 1070 | Full historical archive |
| `ACTIVE_AGENTS.md` | 119 | Agent ID tracking |
| `docs/text-inventory.md` | 139 | Complete text list |
| `docs/claude_md_change_report.md` | 559 | Critical review of changes |

**Key content restored after critical review:**
- Tamil workflow details (SDK spec, --retranslate flag, editorial pass)
- Technical conventions (Unicode, immutability, slugified URLs)
- External resource URLs
- Yashodhara commentary contamination bug warning
- All agent IDs moved to ACTIVE_AGENTS.md

### Genre Categorization Feature — COMPLETE

Added genre/category system to texts for browsing:

**Agent a854600 (Schema + Migration):**
- Added `genre` column to `texts` table in `src/server/db/schema.ts`
- Values: `philosophy`, `commentary`, `literature`, `history`, `science`
- Created `scripts/categorize-texts.ts` migration script
- Categorized all 51 texts
- Updated `docs/text-inventory.md` with genre column

**Genre Distribution:**
| Genre | Count |
|-------|-------|
| Commentary | 16 |
| Literature | 12 |
| History | 8 |
| Philosophy | 8 |
| Science | 7 |

**Agent ad63b5a (Sidebar UI):**
- Added "Explore By Category" section to `src/app/page.tsx`
- Links to `/texts?genre=<genre>` for filtering
- Sorted by count descending (most works first)
- Matches styling of "Explore By Language" section

### Files Modified This Session
- `src/server/db/schema.ts` — Added genre field
- `src/app/page.tsx` — Added category sidebar section
- `scripts/categorize-texts.ts` — New migration script
- `docs/text-inventory.md` — Added genre column to all tables
- `CLAUDE.md` — Reorganized
- `ACTIVE_AGENTS.md` — New file for agent tracking

### Commits Made
1. `010141e` — docs: Reorganize CLAUDE.md with supplementary files

### Pending Commits
- Genre categorization changes (schema + migration + UI)


### CLAUDE.md Documentation Gaps Fixed

Added missing documentation to CLAUDE.md:

1. **Armenian Translation Workflow** — Added section explaining:
   - Must use DeepSeek (Gemini blocks historical content)
   - Script: `scripts/translate-armenian.ts`
   - Prompt location

2. **Armenian "Delays" Bug** — Added to Critical Bugs section:
   - Unicode corruption symptoms
   - Prevention guidelines
   - Fix report reference

3. **Updated Workflow Index** — Added Armenian translation row

4. **Updated Key Directories** — Added `translate-armenian.ts`

